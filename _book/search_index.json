[
["index.html", "AprendeR Presentación", " AprendeR Autores 2019-01-20 Presentación Esto es una edición preliminar en línea de la 2a parte del libro “AprendeR”. El libro está escrito en R Markdown, usando RStudio como editor de texto y el paquete bookdown para convertir los ficheros markdown en un libro. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivadas 4.0 "],
["chap-distr.html", "Lección 1 Distribuciones de probabilidad 1.1 Ejercicios", " Lección 1 Distribuciones de probabilidad R conoce las distribuciones de probabilidad más importantes, incluyendo las que mostramos en la tabla siguiente: \\[ \\begin{array}{lll} \\hline \\textbf{Distribución} &amp; {\\textbf{Nombre en R}} &amp; {\\textbf{Parámetros}}\\\\ \\hline \\mbox{Binomial} &amp;{\\texttt{binom}} &amp; \\mbox{medida de la muestra $n$, probabilidad $p$}\\\\ \\mbox{Geométrica} &amp; {\\texttt{geom}} &amp; \\mbox{$p$}\\\\ \\mbox{Hipergeométrica} &amp; {\\texttt{hyper}} &amp; N,M,n\\\\ \\mbox{Poisson} &amp; {\\texttt{pois}} &amp; \\mbox{esperanza $\\lambda$}\\\\ \\mbox{Uniforme} &amp; {\\texttt{unif}} &amp; \\mbox{mínimo, máximo}\\\\ \\mbox{Exponencial} &amp; {\\texttt{exp}} &amp; \\lambda\\\\ \\mbox{Normal} &amp; {\\texttt{norm}} &amp; \\mbox{media $\\mu$, desviación típica $\\sigma$}\\\\ \\mbox{Khi cuadrado} &amp; {\\texttt{chisq}} &amp; \\mbox{número de grados de libertad}\\\\ \\mbox{t de Student} &amp; {\\texttt{t}} &amp; \\mbox{número de grados de libertad}\\\\ \\mbox{F de Fisher} &amp; {\\texttt{f}} &amp; \\mbox{los dos números de grados de libertad} \\\\ \\hline \\end{array} \\] Para cada una de estas distribuciones, R sabe calcular cuatro funciones, que se obtienen añadiendo un prefijo al nombre de la distribución: la función de densidad, añadiendo el prefijo d la función de distribución de probabilidad, añadiendo el prefijo p; esta función dispone además del parámetro lower.tail que igualado a FALSE calcula la función de distribución de cola superior: la probabilidad de que una variable aleatoria con esta distribución de probabilidad tome un valor estrictamente mayor que uno dado los cuantiles, añadiendo el prefijo q vectores de números aleatorios con esta distribución, añadiendo el prefijo r La función correspondiente se aplica entonces al valor al que queremos aplicar la función y a los parámetros de la distribución (en este orden, y los parámetros en el orden en que los damos en la tabla anterior, cuando hay más de uno). Por ejemplo, sea \\(X\\) una variable aleatoria binomial \\(B(20,0.3)\\), es decir, de tamaño \\(n=20\\) y probabilidad \\(p=0.3\\), y sean \\(f_X\\) su función de densidad y \\(F_X\\) su función de distribución. Calculemos algunos valores de funciones asociadas a esta variable aleatoria. \\(f_X(5)=P(X=5)\\): dbinom(5,20,0.3) ## [1] 0.1788631 Comprobémoslo, recordando que si \\(X\\sim B(n,k)\\), entonces \\(P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\\): choose(20,5)*0.3^5*0.7^15 ## [1] 0.1788631 \\(f_X(8)=P(X=8)\\): dbinom(8,20,0.3) ## [1] 0.1143967 \\(F_X(5)=P(X\\leq 5)\\): pbinom(5,20,0.3) ## [1] 0.4163708 Comprobémoslo, usando que \\(P(X\\leq 5)=\\sum_{k=0}^5 P(X=k)\\): sum(dbinom(0:5,20,0.3)) ## [1] 0.4163708 \\(F_X(8)=P(X\\leq 8)\\): pbinom(8,20,0.3) ## [1] 0.8866685 \\(P(X&gt;8)\\) pbinom(8,20,0.3,lower.tail=FALSE) ## [1] 0.1133315 En efecto: 1-pbinom(8,20,0.3) ## [1] 0.1133315 El cuantil \\(0.5\\) de \\(X\\), o sea, su mediana: el valor \\(x\\) más pequeño tal que \\(P(X\\leq x)\\geq 0.5\\) qbinom(0.5,20,0.3) ## [1] 6 Comprobemos que \\(P(X\\leq 6)\\geq 0.5\\) y en cambio \\(P(X\\leq 5)&lt; 0.5\\): pbinom(qbinom(0.5,20,0.3),20,0.3) ## [1] 0.6080098 pbinom(qbinom(0.5,20,0.3)-1,20,0.3) ## [1] 0.4163708 El cuantil \\(0.25\\) de \\(X\\), es decir, su primer cuartil: qbinom(0.25,20,0.3) ## [1] 5 Un vector aleatorio de 10 valores generado con la variable aleatoria \\(X\\): rbinom(10,20,0.3) ## [1] 4 7 8 9 7 6 9 7 5 4 Dos vectores aleatorios más, de 10 valores cada uno, generados con la variable aleatoria \\(X\\): rbinom(10,20,0.3) ## [1] 8 7 5 10 3 4 9 6 4 7 rbinom(10,20,0.3) ## [1] 7 5 8 7 7 4 5 7 7 6 Del mismo modo, si estamos trabajando con una variable aleatoria \\(Y\\) de Poisson con parámetro \\(\\lambda=5\\): \\(P(Y=8)\\): dpois(8,5) ## [1] 0.06527804 \\(P(Y\\leq 8)\\): ppois(8,5) ## [1] 0.9319064 El cuantil 0.6 de \\(Y\\): qpois(0.6,5) ## [1] 5 Un vector aleatorio de 20 valores generado con la variable aleatoria \\(Y\\): rpois(20,5) ## [1] 6 7 5 5 7 7 5 5 7 7 7 6 8 3 2 6 5 4 3 4 Si no entramos ningún parámetro en las funciones asociadas a la distribución normal, R entiende que se trata de la normal estándar (con media \\(\\mu=0\\) y desviación típica \\(\\sigma=1\\)): por ejemplo, las dos instrucciones siguientes nos dan el valor \\(f_Z(0.3)\\) de la función densidad de una normal estándar \\(Z\\) aplicada a 0.3 (que no es igual a \\(P(Z=0.3)\\)): dnorm(0.3) ## [1] 0.3813878 dnorm(0.3,0,1) ## [1] 0.3813878 Las funciones densidad y distribución de una variable aleatoria se pueden dibujar con la función curve. curve(dnorm(x,0,1.5),-5,5,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;Función densidad de N(0,1)&quot;,cex.main=0.9) curve(pnorm(x,0,1.5),-5,5,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;Función distribución de N(0,1)&quot;,cex.main=0.9) 1.1 Ejercicios Modelo de test (1) Sea \\(f\\) la función de densidad de una variable aleatoria normal con \\(\\mu=0.2\\) y \\(\\sigma=1.2\\). Dad el valor de \\(f(0.5)\\) redondeado a 4 cifras decimales. (2) Sea \\(X\\) una variable aleatoria normal con \\(\\mu=0.2\\) y \\(\\sigma=1.2\\). Dad el valor de \\(P(3\\leq X\\leq 7)\\) redondeado a 4 cifras decimales. (3) Sea \\(X\\) una variable aleatoria \\(B(10,0.2)\\). Dad el valor de \\(P(3\\leq X\\leq 7)\\) redondeado a 4 cifras decimales. (4) Dad una instrucción que calcule la mediana de una lista de 20 números aleatorios generados con distribución \\(B(10,0.2)\\). No deis el resultado, solo la instrucción. Respuestas al test (1) 0.3222 (Lo hemos calculado con round(dnorm(0.5,0.2,1.2),4)) (2) 0.0098 (Lo hemos calculado con round(pnorm(7,0.2,1.2)-pnorm(3,0.2,1.2),4)) (3) 0.3221 (Lo hemos calculado con round(pbinom(7,10,0.2)-pbinom(2,10,0.2),4). También obtenemos el resultado correcto con round(sum(dbinom(3:7,10,0.2)),4). En cambio, con round(pbinom(7,10,0.2)-pbinom(3,10,0.2),4) no se obtiene el resultado correcto: da 0.1208. Pensad por qué aquí hay que restar pbinom(2,10,0.2) y en la pregunta anterior restábamos pnorm(3,0.2,1.2).) (4) median(rbinom(20,10,0.2)) (También sería correcto median(rbinom(20,size=10,prob=0.2)), pero no es necesario dar los nombres de los parámetros si entráis sus valores en el orden correcto, y por eso no los hemos explicado.) "],
["chap-muestreo.html", "Lección 2 Conceptos básicos de muestreo estadístico 2.1 Tipos de muestreo 2.2 Muestreo aleatorio con R 2.3 Guía rápida 2.4 Ejercicios", " Lección 2 Conceptos básicos de muestreo estadístico En todo estudio estadístico hemos de distinguir entre población, que es un conjunto de sujetos con una o varias características que podemos medir y deseamos estudiar, y muestra, un subconjunto de una población. Por ejemplo, si quisiéramos estudiar alguna característica de los estudiantes de grado de la UIB, entenderíamos que estos forman la población de interés, y si entonces escogiéramos al azar 10 estudiantes de cada grado, obtendríamos una muestra de esta población. Pero también podríamos considerar los estudiantes de grado de la UIB como una muestra de la población de los estudiantes universitarios españoles: depende del estudio que queramos realizar. Recordad que, cuando disponemos de un conjunto de datos obtenidos midiendo una o varias características sobre los sujetos de una muestra, podemos llevar a cabo dos tipos de análisis estadístico: Exploratorio o descriptivo: su objetivo es resumir, representar y explicar los datos de la muestra. Para llevarlo a cabo, se usan técnicas de estadística descriptiva como las que hemos descrito en lecciones anteriores. Inferencial o confirmatorio: su objetivo es deducir (inferir), a partir de los datos de la muestra, información significativa sobre el total de la población. A menudo esta inferencia pasa por contrastar una hipótesis sobre alguna propiedad de las características de la población. Las técnicas que se usan en este caso forman la estadística inferencial. Por ejemplo, supongamos que hemos tomado una muestra de estudiantes de la UIB y sabemos sus calificaciones en un semestre concreto y sus números de hermanos. En un estudio exploratorio simplemente describiríamos estos datos mediante estadísticos y gráficos, mientras que usaríamos técnicas de estadística inferencial para deducir información sobre la población de todos los estudiantes de la UIB a partir de esta muestra: ¿Cuál estimamos que ha sido la nota media de los estudiantes de la UIB en el semestre en cuestión? La distribución de los números de hermanos en estudiantes de la UIB, ¿es similar a la del conjunto de la población española? ¿Es verdad que los estudiantes de la UIB con más hermanos tienen tendencia a tener mejores notas? Un estudio inferencial suele desglosarse en los pasos siguientes: Establecer la característica que se desea estimar o la hipótesis que se desea contrastar. Determinar la información (los datos) que se necesita para hacerlo. Diseñar un experimento que permita recoger estos datos; este paso incluye: Decidir qué tipo de muestra se va a tomar y su tamaño. Elegir las técnicas adecuadas para realizar las inferencias deseadas a partir de la muestra que se tomará. Tomar una muestra y medir los datos desados sobre los individuos que la forman. Aplicar las técnicas de inferencia elegidas con el software adecuado. Obtener conclusiones. Si las conclusiones son fiables y suficientes, redactar un informe; en caso contrario, volver a empezar. En la próxima sección nos centramos en las técnicas de muestreo: los métodos generales para seleccionar muestras representativas de una población que tenemos a nuestra disposición en el tercer paso de la lista anterior. 2.1 Tipos de muestreo Existen muchas técnicas de muestreo, cada una de las cuales proporciona una muestra representativa de la población en algún sentido. A continuación describimos de forma breve algunas de estas técnicas. Muestreo aleatorio con y sin reposición Un muestreo aleatorio consiste en seleccionar una muestra de la población de manera que todas las muestras del mismo tamaño sean equiprobables; es decir, que si fijamos el número de individuos de la muestra, cualquier conjunto de ese número de individuos tenga la misma probabilidad de ser seleccionado. Hay dos tipos básicos de muestreo aleatorio que vale la pena distinguir. Para ilustrarlos, supongamos que disponemos de una urna con 100 bolas numeradas del 1 al 100, de la que queremos extraer una muestra de 10 bolas. Una manera de hacerlo sería repetir 10 veces el proceso de sacar una bola de la urna, anotar su número y devolverla a la urna. El tipo de muestra obtenida de esta manera recibe el nombre de muestra aleatoria con reposición, o simple (una m.a.s., para abreviar). Observad que con este procedimiento una misma bola puede aparecer varias veces en una muestra, y que todos los subconjuntos de 10 bolas “con posibles repeticiones” tienen la misma probabilidad de obtenerse. Otra manera de extraer nuestra muestra sería repetir 10 veces el proceso de sacar una bola de la urna pero ahora sin devolverla. Esto es equivalente a extraer de golpe 10 bolas de la urna. Estas muestras no tienen bolas repetidas, y cualquier selección de 10 bolas diferentes tiene la misma probabilidad de ser la obtenida. En este caso se habla de una muestra aleatoria sin reposición. Cuando el tamaño de la población es muy grande en relación a la muestra, la probabilidad de que haya repeticiones en una muestra aleatoria simple es muy pequeña y por lo tanto en este caso entendemos que los muestreos aleatorios con y sin reposición son equivalentes en el sentido siguiente: puesto que una muestra con reposición da muy probablemente una muestra con todos sus elementos diferentes, aceptamos que una muestra obtenida sin reposición ha sido obtenida permitiendo repeticiones y que por tanto es simple. A modo de ejemplo, vamos a calcular la probabilidad de al menos una repetición en muestras aleatorias simples de diferentes tamaños de una población de 12,000 individuos (aproximadamente, el número de estudiantes de la UIB) y representar estas probabilidades en un gráfico. Recordad que la probabilidad de que los sujetos de una muestra aleatoria simple de tamaño \\(n\\) tomada de una población de \\(n\\) individuos sean todos diferentes es \\[ \\frac{N(N-1)(N-2)\\cdots (N-n+1)}{N^n} \\] y por lo tanto la probabilidad de que en una muestra haya algún elemento repetido es 1 menos este valor. Esta probabilidad es la que calcula la función f(N,n) del chunk siguiente. f=function(N,n){1-prod((N:(N-n+1))/N)} prob=sapply(1:200,f,N=12000) plot(1:200,prob,type=&quot;l&quot;,lwd=2, main=&quot;Probabilidad de repetición en una m.a.s.\\n de n estudiantes de la UIB&quot;, xlab=&quot;n&quot;,ylab=&quot;probabilidad&quot;,xaxp=c(0,200,20),yaxp=c(0,1,10)) abline(h=0.01,col=&quot;red&quot;) text(160,0.04,labels=&quot;probabilidad 0.01&quot;,col=&quot;red&quot;,cex=0.7) La curva negra representa las probabilidades deseadas. Hemos añadido al gráfico una línea horizontal que marca la probabilidad 0.01, y muestra que la probabilidad de alguna repetición en una m.a.s. de 16 o menos estudiantes de la UIB es inferior al 1%. Así, por ejemplo, una muestra aleatoria sin reposición de 10 estudiantes de la UIB podría haberse obtenido perfectamente tomando los estudiantes con reposición, porque la probabilidad de alguna repetición en una m.a.s. como esta es muy pequeña: 0.004. En cambio, es difícil de creer que una muestra aleatoria de 200 estudiantes diferentes de la UIB sea simple, porque la probabilidad de alguna repetición en una m.a.s. como esta es grande: 0.811. La mayoría de fórmulas que daremos en este curso suponiendo que trabajamos con una muestra aleatoria simple las consideraremos igualmente válidas para muestras aleatorias sin reposición, siempre y cuando el tamaño de la población sea muy grande en relación al de la muestra (por dar una regla, como mínimo unas 1000 veces mayor). Si el tamaño de la población es relativamente pequeño por comparación a la muestra, algunas de estas fórmulas se pueden salvar aplicando correcciones adecuadas para compensar el efecto del tamaño de la población, y otras directamente pierden toda validez. En todo caso, conviene remarcar que para tomar una muestra aleatoria con o sin reposición de una población, es necesario disponer de una lista completa de todos sus individuos, para sortear a quién vamos a seleccionar. Esto no siempre es posible. ¿Alguien tiene la lista completa de, pongamos, todos los diabéticos de España? ¿Que incluya los que aún no saben que lo son? Por lo tanto, en la vida real no siempre podemos tomar muestras aleatorias en el sentido que hemos explicado. Muestreo sistemático Una manera muy sencilla de obtener una muestra de una población cuando disponemos de una lista ordenada de sus individuos es tomarlos a intervalos constantes: cada quinto individuo, cada décimo individuo. Podemos añadir una componente aleatoria escogiendo al azar el primer individuo que elegimos, y a partir del cual empezamos a contar. Así, por ejemplo, si de una clase de 100 estudiantes quisiéramos escoger una muestra de 10, podríamos elegir un estudiante al azar, y a partir de él, por orden alfabético, elegir el décimo estudiante, el vigésimo, el trigésimo, etc.; si al llegar al final de la lista de clase no hubiéramos completado la muestra, volveríamos al principio de la misma. A esta técnica se la llama muestreo sistemático, aleatorio si además el primer sujeto se escoge de manera aleatoria. Cuando no disponemos de una lista de toda la población pero sí que tenemos una manera de acceder de manera ordenada a sujetos de la misma (por ejemplo, enfermos que acuden a un hospital), podemos realizar un muestreo sistemático tomando los sujetos a intervalos constantes a medida que los encontramos hasta completar el tamaño deseado de la muestra. Por ejemplo, para escoger una muestra de 10 estudiantes, podríamos escoger cada décimo estudiante que entrase en un edificio del Campus por una puerta concreta hasta llegar a los 10. Cuando el orden de los individuos de la población en la lista es aleatorio, el muestreo sistemático aleatorio es equivalente al muestreo aleatorio sin reposición. Pero en general este no es el caso, y se pueden producir sesgos. Por poner un caso extremo, si una clase de 100 estudiantes estuviera formada por 50 parejas de hermanos y tomáramos una muestra sistemática de 50 estudiantes, eligiéndolos por orden alfabético de los apellidos uno sí, uno no, es seguro que no aparecería ninguna pareja de hermanos en la muestra (porque dos hermanos son siempre consecutivos en la lista, y en nuestra muestra no hay ningún par de sujetos consecutivos). En cambio, la probabilidad de que una muestra aleatoria sin reposición del mismo tamaño contuviera una pareja de hermanos es prácticamente 1; en concreto esta probabilidad sería \\[ \\frac{100\\times 98\\times 96\\times\\cdots\\times 2}{100\\times 99\\times 98\\times\\cdots\\times 51}=\\frac{2^{50}\\cdot 50!^2}{100!}=0.999999999999989. \\] Muestreo aleatorio estratificado Este tipo de muestreo se utiliza cuando la población está clasificada en grupos o estratos que son de interés para la propiedad estudiada. En este caso, se toma una muestra aleatoria de cada estrato y se unen en una muestra global. A este proceso se le llama muestreo aleatorio estratificado. Normalmente, se impone que la composición por estratos de la muestra global mantenga las proporciones de la población original; es decir, que el tamaño de la muestra de cada estrato represente el mismo porcentaje del total de la muestra que el estrato correspondiente en la población completa. Por ejemplo, los estratos podrían ser grupos de edad, y entonces la muestra de cada grupo de edad se tomaría proporcional a la fracción que representa dicho grupo de edad en la población total. O podrían ser los sexos anatómicos, y procuraríamos que nuestra muestra estuviera formada por un 50% de hombres y un 50% de mujeres. O, en las Islas Baleares, los estratos podrían ser las islas, de manera que la muestra tomada en cada isla fuera proporcional a la población relativa de la misma dentro del conjunto total de la comunidad autónoma. En todo caso, el muestreo por estratos solo es necesario si esperamos que las características de la propiedad poblacional que queremos estudiar varíen según el estrato. Por ejemplo, si queremos tomar una muestra para estimar la altura media de los españoles adultos y no creemos que la altura de un español adulto dependa de su provincia de origen, no hay ninguna necesidad de esforzarse en tomar una muestra de cada provincia de manera que todas las provincias estén representadas proporcionalmente en la muestra. Muestreo por conglomerados El proceso de obtener y estudiar una muestra aleatoria en algunos casos es caro o difícil, incluso aunque dispongamos de la lista completa de la población. Imaginemos que quisiéramos estudiar los hábitos de alimentación de los estudiantes de Primaria de Baleares. Para ello, previo permiso de la autoridad competente, tendríamos que seleccionar una muestra representativa de los escolares de Baleares. Seguramente podríamos disponer de su lista completa y por lo tanto podríamos tomar una muestra aleatoria, pero entonces acceder a las niñas y niños que la formasen seguramente significaría contactar con unos pocos alumnos de muchos centros de primaria, lo que volvería el proceso lento y costoso. Y eso si la Conselleria d’Educació nos facilitase la lista completa de alumnos. Una alternativa posible sería, en vez de extraer una muestra aleatoria de todos los estudiantes de Primaria, escoger primero al azar unas pocas aulas de primaria de colegios de las Baleares, a las que llamamos en este contexto conglomerados (clusters), y formar entonces nuestra muestra con todos los alumnos de estas aulas. Y es que es mucho más sencillo poseer la lista completa de estudiantes de unas pocas aulas que conseguir la lista completa de todos los estudiantes de todos los colegios, y mucho más barato ir a unos pocos colegios concretos que ir a todos los colegios de las Islas a entrevistar a unos pocos estudiantes en cada centro. Efectuamos también un muestreo por conglomerados cuando para medir algunas características de los ejemplares de una planta en un bosque concreto, cuadriculamos la superficie del bosque, escogemos una muestra aleatoria de sectores de la cuadrícula (serían los conglomerados de este ejemplo) y estudiamos las plantas de interés contenidas en los sectores elegidas. Muestreos no aleatorios Cuando la selección de la muestra no es aleatoria, se habla de muestreo no aleatorio. En realidad es el tipo más frecuente de muestreo porque, en muchos casos, nos tenemos que conformar con los sujetos disponibles. Por ejemplo, en la UIB, para estimar la opinión que de un profesor tienen los alumnos de una clase, se consulta solo a los estudiantes que voluntariamente rellenan la encuesta de opinión, que de ninguna manera forman una muestra aleatoria: el perfil del estudiante que contesta voluntariamente una encuesta de este tipo está muy definido y no viene determinado por el azar. En este caso se trataría de una muestra autoseleccionada. Otro tipo de muestreos no aleatorios son los oportunistas. Este es el caso, por ejemplo, si para estimar la opinión que de un profesor tienen los alumnos de una clase se visita la clase y se pasa la encuesta a los estudiantes que ese día asistieron a clase. De nuevo, puede que los alumnos presentes no sean representativos del alumnado de la asignatura (puede que sean los más aplicados, o los que no tienen la gripe, o a los que la asignatura no les coincide con otra). Veamos otros ejemplos de muestreo oportunista. Supongamos que queremos estudiar una característica de los animales de una determinada especie en un hábitat, y la medimos en los animales que capturamos u observamos. Estos ejemplares no tienen por qué ser representativos de la población: a lo mejor son los menos espabilados. O imaginad que tenéis una bolsa con bolas de diferentes tamaños. Si las removéis bien, las pequeñas tenderán a ir a parar al fondo y las grandes a quedar en la parte superior. Por lo tanto, si tomáis una muestra de la capa superior (que será lo más cómodo), no será representativa del total de la bolsa. Las técnicas de estadística inferencial no se pueden aplicar a muestras no aleatorias, pero normalmente son las únicas que podemos conseguir. En este caso, lo que se suele hacer es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, es representativa de la población y podría haber sido aleatoria. Muestreo polietápico En el ejemplo de los estudiantes de Primaria, la muestra final de estudiantes ha estado formada por todos los individuos de las aulas elegidas. Otra opción podría haber sido, tras seleccionar la muestra aleatoria de conglomerados, tomar de alguna manera una muestra aleatoria de cada uno de ellos. Por ejemplo, algunos estudios poblacionales a nivel estatal se realizan solamente en algunas provincias escogidas aleatoriamente, en las que luego se encuesta una muestra aleatoria de habitantes. Este sería un ejemplo de muestreo polietápico, en el que la muestra no se obtiene en un solo paso, sino mediante diversas elecciones sucesivas. Otro ejemplo enrevesado (pero real) de muestreo polietápico sería, para elegir una muestra de adolescentes de una ciudad grande, escoger en primer lugar 4 secciones censales al azar; a continuación, escoger al azar 10 manzanas de cada una de estas secciones censales y una esquina de cada manzana; finalmente, recorrer cada manzana en sentido horario a partir de la esquina seleccionada y visitar un portal de cada tres, entrevistando todos los habitantes de 13 a 19 años en las casas o fincas visitadas. En este proceso, hemos realizado dos muestreos aleatorios sin reposición (de secciones censales y de manzanas) y un muestreo sistemático aleatorio (los portales). Si además los adolescentes que estudiamos al final no son todos los que viven en los portales seleccionados sino solo los que encontramos en casa el día que los visitamos, este muestreo oportunista significaría un cuarto paso en la formación de la muestra. Existen otros tipos de muestreo, solo hemos explicado los más comunes. En cualquier caso, lo importante es recordar que el estudio estadístico que se realice a posteriori deberá ser diferente según el muestreo usado. Por ejemplo, no se pueden usar las mismas técnicas para analizar una muestra aleatoria simple que una muestra por conglomerados. 2.2 Muestreo aleatorio con R En este curso estudiaremos las propiedades de las diferentes técnicas de estimación solamente para el caso de muestreo aleatorio simple, es decir, al azar y con reposición, o al azar sin reposición si la población es muy, muy grande en comparación con la muestra. Recordemos que un método de selección al azar de muestras de tamaño \\(n\\) (es decir, formadas por \\(n\\) individuos) de una cierta población produce muestras aleatorias simples (m.a.s.) cuando todas las muestras posibles de \\(n\\) individuos (con posibles repeticiones) tienen la misma probabilidad de ser elegidas. El tener una m.a.s. de una población junto con un tamaño muestral adecuado \\(n\\) nos asegurará que la estimación que hagamos sea muy probablemente correcta. La manera más sencilla de llevar a cabo un muestreo aleatorio simple es numerar todos los individuos de una población y sortearlos eligiendo números de uno en uno como si se tratase de una lotería, por ejemplo con algún generador de números aleatorios. Esto se puede llevar a cabo fácilmente con R. R dispone de un generador de muestras aleatorias de un vector. La función básica es sample(x, n, replace=...) donde: x es un vector o un número natural \\(x\\), en cuyo caso R entiende que representa el vector 1,2,…,\\(x\\); n es el tamaño de la muestra que deseamos extraer; el parámetro replace puede igualarse a TRUE, y será una muestra aleatoria simple, es decir, con reposición, o a FALSE, y será una muestra aleatoria sin reposición. Este último es su valor por defecto, por lo que no es necesario especificarlo si se quiere obtener una muestra sin reposición. Los dos primeros parámetros han de entrarse en este orden o igualados a los parámetros x y size, respectivamente. Así, por ejemplo, para obtener una m.a.s. de 15 números entre 1 y 100, podemos entrar: sample(100,15,replace=TRUE) ## [1] 67 20 86 9 76 67 37 59 73 7 73 56 3 30 22 Naturalmente, y como ya nos encontramos en la Lección 1 cuando generábamos vectores aleatorios con una distribución dada, cada ejecución de sample con los mismos parámetros puede dar lugar a muestras diferentes, y todas ellas tienen la misma probabilidad de aparecer: sample(100,15,replace=TRUE) ## [1] 82 95 17 88 16 18 43 35 68 42 64 71 30 81 29 sample(100,15,replace=TRUE) ## [1] 43 16 74 99 8 81 64 78 25 23 64 82 6 37 33 sample(100,15,replace=TRUE) ## [1] 79 100 56 4 94 46 6 80 88 100 40 90 93 61 58 Veamos cómo extraer una m.a.s de una tabla de datos. Recordemos el data frame iris, que recoge medidas de pétalos y sépalos de 150 flores de tres especies de iris. str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Si queremos extraer una m.a.s. de 15 ejemplares (filas) de esta tabla de datos, podemos generar con sample una m.a.s. de índices de filas de la tabla y a continuación crear un data frame que contenga solo estas filas: x=sample(dim(iris)[1],15,replace=TRUE) #Los índices de la m.a.s. muestra_iris=iris[x,] #La m.a.s. de la tabla iris muestra_iris ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 78 6.7 3.0 5.0 1.7 versicolor ## 103 7.1 3.0 5.9 2.1 virginica ## 145 6.7 3.3 5.7 2.5 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 105 6.5 3.0 5.8 2.2 virginica ## 44 5.0 3.5 1.6 0.6 setosa ## 140 6.9 3.1 5.4 2.1 virginica ## 95 5.6 2.7 4.2 1.3 versicolor ## 3 4.7 3.2 1.3 0.2 setosa ## 79 6.0 2.9 4.5 1.5 versicolor ## 98 6.2 2.9 4.3 1.3 versicolor ## 116 6.4 3.2 5.3 2.3 virginica ## 71 5.9 3.2 4.8 1.8 versicolor ## 5 5.0 3.6 1.4 0.2 setosa ## 5.1 5.0 3.6 1.4 0.2 setosa Recordad que dim aplicado a un dataframe nos da un vector con sus dimensiones: sus números de filas y de columnas, en este orden. Por lo tanto, dim(iris)[1] es el número de filas de iris. Si solo quisiéramos una muestra aleatoria de longitudes de pétalos, podríamos aplicar directamente la función sample al vector correspondiente: muestra_long_pet=sample(iris$Petal.Length,15,replace=TRUE) muestra_long_pet ## [1] 4.7 1.4 4.2 4.7 5.0 1.4 4.1 6.0 6.1 5.8 5.1 5.1 1.4 4.4 5.6 El hecho de que funciones como sample o los generadores de vectores aleatorios con una cierta distribución de probabilidad fijada, como rnorm o rbinom, produzcan… pues eso, vectores aleatorios, puede tener inconvenientes a la hora de reproducir una simulación. R permite “fijar” el resultado de una función aleatoria con la instrucción set.seed. Sin entrar en detalles sobre cómo funcionan, los diferentes algoritmos que usa R para generar números aleatorios usan una semilla de aleatoriedad, que se modifica después de la ejecución del algoritmo, y por eso cada vez dan un resultado distinto. Pero, para una semilla fija, el algoritmo da el mismo resultado siempre. Lo que hace la función set.seed es igualar esta semilla al valor que le entramos. Si tras aplicar esta función a un número concreto ejecutamos una instrucción que genere un vector aleatorio de una longitud fija con una distribución fija, el resultado será siempre el mismo. Veamos un ejemplo de su efecto, generando muestras aleatorias simples de 10 longitudes de pétalos de flores iris con diferentes semillas de aleatoriedad: sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.1 1.0 5.9 1.5 3.3 5.1 5.1 4.8 6.4 4.9 set.seed(20) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.4 5.3 1.3 3.5 5.7 5.2 1.1 1.5 1.4 4.5 set.seed(20) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.4 5.3 1.3 3.5 5.7 5.2 1.1 1.5 1.4 4.5 sample(iris$Petal.Length,10,replace=TRUE) ## [1] 6.3 5.0 1.4 5.3 1.4 4.1 1.5 1.3 1.6 6.7 set.seed(10) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 4.8 1.6 3.6 5.6 1.4 1.4 1.3 1.3 4.0 3.6 set.seed(10) sample(iris$Petal.Length,10,replace=TRUE) ## [1] 4.8 1.6 3.6 5.6 1.4 1.4 1.3 1.3 4.0 3.6 Ejecutado inmediatamente después de set.seed(20), sample(iris$Petal.Length,10,replace=TRUE) siempre da lo mismo. Y ejecutado después de set.seed(10), sample(iris$Petal.Length,10,replace=TRUE) vuelve a dar siempre da lo mismo, pero diferente de con set.seed(20). La función set.seed no solo fija el resultado de la primera instrucción tras ella que genere un vector aleatorio, sino que, como fija la semilla de aleatoriedad y las funciones posteriores la modificarán de manera determinista, también fija los resultados de todas las instrucciones siguientes que generen vectores aleatorios. set.seed(100) sample(10,3) ## [1] 4 3 5 sample(10,3) ## [1] 1 5 4 sample(10,3) ## [1] 9 4 5 set.seed(100) sample(10,3) ## [1] 4 3 5 sample(10,3) ## [1] 1 5 4 sample(10,3) ## [1] 9 4 5 Si queréis volver a “reiniciar” la semilla de la aleatoriedad tras haber usado un set.seed, podéis usar set.seed(NULL). set.seed(100) sample(10,3) ## [1] 4 3 5 set.seed(NULL) sample(10,3) ## [1] 8 4 7 set.seed(100) sample(10,3) ## [1] 4 3 5 set.seed(NULL) sample(10,3) ## [1] 8 9 3 A veces querremos tomar diversas muestras aleatorias de una misma población y calcular algo sobre ellas. Para hacerlo podemos usar la función replicate. La sintaxis básica es replicate(n, instrucción) donde n es el número de repeticiones de la instrucción. Por ejemplo, para tomar 10 muestras aleatorias simples de 15 longitudes de pétalos de flores iris, podemos hacer: muestras=replicate(10, sample(iris$Petal.Length,15,replace=TRUE)) muestras ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 6.1 6.7 4.0 1.5 5.0 5.4 4.7 3.5 4.5 1.3 ## [2,] 6.4 3.3 1.9 3.9 6.1 5.1 1.4 5.0 1.6 1.4 ## [3,] 4.7 4.5 6.1 3.8 1.5 1.5 4.2 4.5 1.6 4.5 ## [4,] 4.0 4.1 5.9 4.5 4.7 4.2 4.0 5.6 4.5 4.6 ## [5,] 4.8 3.3 4.9 5.0 1.5 5.5 3.5 4.7 1.4 5.0 ## [6,] 3.5 5.1 1.6 6.1 1.7 4.1 4.0 1.5 3.9 5.5 ## [7,] 1.4 1.5 4.5 5.5 5.5 4.5 4.4 3.0 1.6 4.4 ## [8,] 4.8 5.7 4.5 5.1 4.1 5.0 4.5 5.0 1.6 6.7 ## [9,] 1.4 4.6 5.0 1.6 4.0 5.9 1.6 5.5 4.2 4.5 ## [10,] 6.6 5.4 5.4 3.3 3.7 4.5 1.6 1.4 1.6 1.7 ## [11,] 6.3 4.3 1.7 5.8 3.6 5.0 4.9 1.3 5.1 5.7 ## [12,] 5.2 5.9 5.1 4.5 4.4 4.7 1.5 5.1 1.7 1.7 ## [13,] 1.7 1.5 3.7 4.6 1.3 1.5 6.1 1.5 1.4 5.1 ## [14,] 6.4 5.0 1.9 5.9 3.0 6.1 3.6 3.5 1.6 1.2 ## [15,] 5.6 3.6 5.4 5.1 4.0 3.5 4.2 1.5 5.6 4.2 Observad que R ha organizado los 10 vectores generados con el replicate como columnas de una matriz. Si, por ejemplo, solo nos hubiera interesado calcular las medias, redondeadas a 2 cifras decimales, de 10 muestras aleatorias simples de 15 longitudes de pétalos de flores iris, podríamos haber hecho medias=replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) medias ## [1] 4.20 4.14 4.45 4.37 3.29 3.40 2.70 3.85 4.07 3.43 En este caso, como el resultado de la instrucción que iteramos es un solo número, los resultados del replicate forman un vector. ¿Y si quisiéramos la media y la desviación típica muestral de 10 muestras de estas? No podemos usar sin más dos replicate, como en replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 4.00 3.99 4.15 3.96 3.87 3.52 2.79 3.82 3.47 4.27 replicate(10,round(sd(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 1.91 1.94 1.92 1.09 1.82 1.96 1.73 1.66 1.80 1.74 porque el conjunto de muestras de las que hemos calculado la media en el primer replicate muy probablemente habrá sido diferente del conjunto de muestras de las que hemos calculado la desviación típica en el segundo replicate. Lo más adecuado es definir una función que calcule un vector con estos dos valores, y luego usarla dentro de un único replicate. info=function(x){round(c(mean(x),sd(x)),2)} info_lp=replicate(10,info(sample(iris$Petal.Length,15,replace=TRUE))) info_lp ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 3.57 3.26 4.27 3.11 3.02 3.54 3.07 3.69 3.59 3.17 ## [2,] 2.08 1.77 1.70 1.94 1.91 1.73 1.83 1.44 1.93 1.57 En este último caso, R ha organizado la información obtenida como columnas de una matriz: la primera fila son las medias y la segunda las desviaciones típicas. Naturalmente, la función set.seed permite “fijar” el resultado de un replicate que incluya la generación de números aleatorios: set.seed(1000) replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 3.63 3.18 4.05 4.59 4.13 2.51 3.61 3.31 3.63 3.96 set.seed(1000) replicate(10,round(mean(sample(iris$Petal.Length,15,replace=TRUE)),2)) ## [1] 3.63 3.18 4.05 4.59 4.13 2.51 3.61 3.31 3.63 3.96 Para terminar esta lección, damos una función sencilla para efectuar muestreos sistemáticos aleatorios. El objetivo es, dado un vector de longitud \\(N\\), obtener una muestra de tamaño \\(n\\). Lo que haremos será tomar el cociente por exceso \\(k=\\lceil N/n\\rceil\\) de \\(N\\) entre \\(n\\) para determinar el período con el que tenemos que tomar los elementos de manera que todos los elementos puedan ser escogidos. A continuación elegimos al azar un elemento del vector con sample y a partir de él generamos una progresión artitmética de \\(n\\) elementos y paso \\(k\\), volviendo al inicio del vector si llegamos al final sin haber completado la muestra. sist.sample=function(N,n){ k=ceiling(N/n) x0=sample(N,1) seq(x0,x0+k*(n-1),k)%%N } Por ejemplo, una muestra sistemática de 10 flores iris (como 150/10=15, los índices avanzarán de 15 en 15 a partir de uno generado al azar): x=sist.sample(dim(iris)[1],10) #Los índices de la muestra sistemática muestra_sist_iris=iris[x,] #La muestra de la tabla iris muestra_sist_iris ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 49 5.3 3.7 1.5 0.2 setosa ## 64 6.1 2.9 4.7 1.4 versicolor ## 79 6.0 2.9 4.5 1.5 versicolor ## 94 5.0 2.3 3.3 1.0 versicolor ## 109 6.7 2.5 5.8 1.8 virginica ## 124 6.3 2.7 4.9 1.8 virginica ## 139 6.0 3.0 4.8 1.8 virginica ## 4 4.6 3.1 1.5 0.2 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 34 5.5 4.2 1.4 0.2 setosa 2.3 Guía rápida sample(x, n, replace=...) genera una muestra aleatoria de tamaño n del vector x, con reposición si igualamos replace a TRUE y sin reposición si lo igualamos a FALSE (su valor por defecto). Si x es un número natural \\(x\\), representa el vector 1,2,…,\\(x\\). set.seed permite fijar la semilla de aleatoriedad. replicate(n,expresión) evalúa n veces la expresión, y organiza los resultados como las columnas de una matriz (o un vector, si el resultado de cada expresión es unidimensional). 2.4 Ejercicios Modelo de test (1) Queremos escoger 100 estudiantes de grado de la UIB para preguntarles cuántas horas semanales estudian. Como creemos que el tipo de estudio cursado influye en este dato, clasificaremos los estudiantes según el centro (facultad o escuela) en el que están matriculados, y tomaremos una muestra al azar de cada centro, por sorteo a partir de la lista de todos los matriculados en ese centro y de manera que el tamaño de la muestra de cada centro sea proporcional al número de matriculados en el mismo. ¿De qué tipo de muestreo se tratará? Muestreo aleatorio simple Muestreo aleatorio estratificado Muestreo aleatorio sin reposición Muestreo aleatorio por conglomerados Muestreo aleatorio sistemático Ninguno de los anteriores (2) Con una sola instrucción, calculad la media de una muestra aleatoria sin reposición de 15 elementos escogidos de un vector numérico llamado \\(X\\). (3) Con una sola instrucción, extraed un subdataframe del dataframe iris formado por una muestra aleatoria sin reposición de 40 filas, y llamadlo muestra. Y antes de contestar, comprobad que funciona. (4) Con una sola instrucción, calculad un vector formado por las medias de 100 muestras aleatorias sin reposición de 20 elementos cada una escogidos de un vector numérico llamado \\(X\\) y llamadlo medias. Ejercicios 1) Considerad la tabla de datos que encontraréis en http://www.hofroe.net/stat557/data/crab.txt y que contiene información sobre una muestra de cangrejos. Cargadla en un dataframe. (a) Definid una función de parámetros s, n y N que calcule la media y la desviación típica muestral del vector formado por las medias de los pesos de los individuos de cada una de las \\(N\\) muestras aleatorias simples de \\(n\\) filas de dicha tabla obtenidas usando como semilla de aleatoriedad el número \\(s\\). Tenéis que usar set.seed y replicate para definir la función. (b) Aplicadla a \\(N\\)=100, \\(n\\)=30 y tomando como \\(s\\) el número formado por las 5 primeras cifras de vuestro NIF o pasaporte. (c) ¿Qué valores predice el Teorema Central del Límite que se deberían obtener? ¿Habéis obtenido resultados similares a los predichos por dicho teorema? 2) Extraed una muestra aleatoria estratificada de 15 flores de la tabla iris manteniendo en la muestra las proporciones de las diferentes especies en la tabla. Procurad que el método empleado sea lo más general posible, para poderlo aplicar a cualquier data frame, cualquier tamaño de muestra (aproximadamente) y una clasificación definida por cualquier factor del data frame. Respuestas al test (1) (b) (2) mean(sample(X,15)) (También sería correcto sum(sample(X,15))/15. Y en ambos casos también sería correcto añadiendo replace=FALSE, que hemos omitido porque es el valor por defecto de replace.) (3) muestra=iris[sample(dim(iris)[1],40),] (También sería correcto consultar antes el número de filas con str o tail, ver que son 150, y responder muestra=iris[sample(150,40),]. Hay otras respuestas correctas, no las damos para no liaros. Además, y como antes, también sería correcto añadir replace=FALSE.) (4) medias=replicate(100,mean(sample(X,20))) (¿Ya os hemos dicho que también sería correcto con replace=FALSE?) Soluciones sucintas a los ejercicios 1) (a) DCR=read.table(&quot;http://www.hofroe.net/stat557/data/crab.txt&quot;,header=TRUE) M=function(n,N,s){ set.seed(s) Muestras=replicate(N,mean(sample(DCR$Weight,n,replace=TRUE))) Res=round(c(mean(Muestras),sd(Muestras)),2) attr(Res,&quot;names&quot;)=c(&quot;Media&quot;,&quot;Desv. Típica&quot;) Res } (b) M(30,100,00) ## Media Desv. Típica ## 2427.91 109.58 (c) El TCL predice como media la de la población (el vector de pesos) round(mean(DCR$Weight),2) ## [1] 2437.19 y como desviación típica la desviación típica de la población dividida por la raíz cuadrada del tamaño de las muestras round((sd(DCR$Weight)*sqrt(length(DCR$Weight)-1)/sqrt(length(DCR$Weight)))/sqrt(30),2) ## [1] 105.04 2) Por ejemplo Clust_sample=function(DF,Fact,n){ attach(DF) Tamaños=round(prop.table(table(Fact))*n) Muestra=c() for(i in 1:length(levels(Fact))){ Muestra=c(Muestra,sample(which(Fact==levels(Fact)[i]),Tamaños[i])) } detach(DF) Muestra } Clust_sample(iris,Species,15) ## [1] 27 40 24 9 19 91 97 59 67 83 148 121 107 139 138 Una construcción equivalente, sin usar un bucle for Clust_sample=function(DF,Fact,n){ attach(DF) M=length(levels(Fact)) Tamaños=round(prop.table(table(Fact))*n) F=function(i){sample(which(Fact==levels(Fact)[i]),Tamaños[i])} Muestra=as.vector(sapply(1:M,FUN=F)) detach(DF) Muestra } Clust_sample(iris,Species,15) ## [1] 46 35 23 4 34 97 52 56 69 58 106 115 128 107 123 "],
["estimacion.html", "Lección 3 Estimación puntual 3.1 Estimación máximo verosímil 3.2 Guía rápida 3.3 Ejercicios", " Lección 3 Estimación puntual En un estudio inferencial, una vez tomada la muestra y obtenidos los datos sobre sus miembros, el siguiente paso es inferir, es decir, deducir información sobre la población a partir de estos datos. Dicha información se puede deducir de dos formas: Suponiendo que conocemos el modelo al que se ajusta la población: es decir, suponiendo que conocemos el tipo de distribución de la variable aleatoria que modela la característica de la población en la que estamos interesados, pero desconocemos uno o varios parámetros de los que depende dicha distribución (notad que si lo sabemos todo sobre esta distribución, ya no hace falta tomar muestras para inferir algo sobre ella). Así, podemos saber (o suponer) que las longitudes de los ejemplares adultos de una cierta especie se distribuyen según una variable aleatoria normal, pero desconocer sus parámetros \\(\\mu\\) (media) y \\(\\sigma\\) (desviación típica), y usar este conocimiento para inferir información sobre dichas longitudes a partir de las de una muestra: por ejemplo, para estimar con un cierto margen de error su longitud media. Si estamos en este caso, hablaremos de estimación paramétrica. Suponiendo que desconocemos qué tipo de distribución tiene la variable aleatoria que modela la característica que nos interesa (aunque a veces necesitaremos saber algo de esta distribución; por ejemplo, si es simétrica o no). En este caso, hablaremos de estimación no paramétrica. En ambos casos, existen tres vías para obtener información sobre los parámetros de la distribución (conocida o desconocida) de la variable aleatoria que nos interesa: Estimación puntual. Se trata de obtener expresiones matemáticas, llamadas estimadores puntuales, que aplicadas a los valores de una muestra nos dan una aproximación (el término exacto es una estimación) del valor de dicho parámetro para la población. A modo de ejemplo, la media aritmética de los datos \\(x_1,\\ldots,x_n\\) de una muestra, \\[ \\overline{x}=\\frac{x_1+\\cdots +x_n}{n}, \\] es un estimador del valor medio (valor esperado, esperanza) de la variable aleatoria de la que hemos extraído la muestra. Estimación por intervalos de confianza. Se trata de obtener intervalos que contengan con probabilidad alta el parámetro objeto de estudio. Trataremos este tema en la Lección 4. Contraste de hipótesis. Grosso modo, se establecen dos hipótesis opuestas sobre el parámetro o, más en general, sobre la distribución de la variable aleatoria, y se contrastan para intentar decidir cuál es la verdadera. Los estudiaremos en próximas lecciones. En esta lección hablaremos de la estimación puntual. Para empezar, es obvio que no toda fórmula matemática sirve para estimar de manera sensata el valor de un parámetro. Por ejemplo, si queréis estimar la media de las alturas de los habitantes de una población y disponéis de una muestra aleatoria de las mismas, no tomáis la raíz cuadrada de la altura máxima en la muestra como estimación de la altura media de la población, ¿verdad? Lo que habéis hecho toda la vida, y seguiréis haciendo en este curso, ha sido calcular la media de las alturas en la muestra y dar ese valor como estimación de la altura media poblacional. Y es lo correcto, porque la media muestral es siempre un estimador insesgado de la media poblacional y muy a menudo es además su estimador máximo verosímil, Veamos qué significan estas propiedades. Los valores de un estimador sobre muestras aleatorias de una población forman una variable aleatoria con una distribución de probabilidad propia, llamada genéricamente muestral. Decimos entonces que un estimador es insesgado cuando el valor esperado de la variable aleatoria que define coincide con el valor del parámetro poblacional que se quiere estimar. Por ejemplo, si se toman muestras aleatorias con o sin reposición, la media muestral es siempre un estimador insesgado del valor medio poblacional. Cada muestra aleatoria de una población tiene una probabilidad de obtenerse que no solo depende de la muestra, sino también de la distribución de probabilidad de la variable aleatoria poblacional. Si la distribución poblacional es de un tipo concreto (Bernoulli, normal, …), esta probabilidad depende de sus parámetros. Decimos entonces que un estimador es máximo verosímil cuando el valor que da sobre cada muestra aleatoria es el valor del parámetro que maximiza la probabilidad de obtenerla. Por ejemplo, si lanzamos una moneda al aire \\(n\\) veces y calculamos la proporción de veces que obtenemos cara, esa proporción muestral \\(\\widehat{p}\\) es el estimador máximo verosímil de la probabilidad \\(p\\) de obtener cara con esa moneda. Esto quiere decir que, de entre todas las distribuciones binomiales \\(B(n,p)\\) que pueden modelar el número de caras que obtenemos al lanzar \\(n\\) veces nuestra moneda, aquella que asigna mayor probabilidad al número de caras que hemos obtenido es la que tiene como \\(p\\) la frecuencia relativa de caras \\(\\widehat{p}\\) que hemos observado. Para algunas distribuciones, el método de máxima verosimilitud de estimación de sus parámetros da lugar a fórmulas cerradas más o menos sencilla, pero en otros casos nos tenemos que conformar con un valor aproximado obtenido mediante algún método numérico. 3.1 Estimación máximo verosímil A continuación recordamos una lista de los estimadores máximo verosímiles de los parámetros de las distribuciones más comunes a partir de una muestra aleatoria simple: Para la familia Bernoulli, el estimador máximo verosímil del parámetro \\(p\\) es la proporción muestral de éxitos \\(\\widehat{p}\\). Este estimador es además insesgado. Para la familia Poisson, el estimador máximo verosímil del parámetro \\(\\lambda\\) es la media muestral \\(\\overline{X}\\). Este estimador es de nuevo insesgado. Para la familia geométrica, el estimador máximo verosímil del parámetro \\(p\\) es \\({1}/{\\overline{X}}\\). Este estimador es sesgado. Para la familia exponencial, el estimador máximo verosímil del parámetro \\(\\lambda\\) es \\({1}/{\\overline{X}}\\). Este estimador también es sesgado. Para la familia normal, los estimadores máximo verosímiles de la media \\(\\mu\\), la desviación típica \\(\\sigma\\) y la varianza \\(\\sigma^2\\) son, respectivamente, la media muestral \\(\\overline{X}\\), la desviación típica “verdadera” \\(S_X\\) y la varianza “verdadera” \\(S_X^2\\). Además, \\(\\overline{X}\\) es un estimador insesgado de \\(\\mu\\). La varianza verdadera \\(S_X^2\\) no es un estimador insesgado de \\(\\sigma^2\\), pero sí que lo es la varianza muestral \\(\\widetilde{S}^2\\). Y ninguna de las dos desviaciones típicas, “verdadera” \\(S_X\\) o muestral \\(\\widetilde{S}_X\\), es un estimador insesgado de \\(\\sigma\\); si necesitáis un estimador insesgado de la desviación típica de una variable aleatoria normal a partir de una muestra aleatoria simple, lo podéis encontrar en la correspondiente entrada de la Wikipedia. No obstante, el beneficio de usar este estimador insesgado no suele compensar lo complicado de su cálculo. Cuando se estima algún parámetro de una distribución a partir de una muestra, es conveniente aportar el error típico, o estándar, como medida de la finura de la estimación. Recordemos que el error típico de un estimador es la desviación típica de su distribución muestral, y que el error típico de una estimación a partir de una muestra es la estimación del error típico del estimador usando dicha muestra. Como veremos en próximas lecciones, estos errores típicos serán una ingrediente clave en el cálculo (en realidad, también una estimación) del margen de error con el que efectuamos nuestra estimación. Veamos un ejemplo sencillo. Supongamos que tenemos una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(X\\) que sigue una distribución Bernoulli de probabilidad poblacional \\(p\\) desconocida que queremos estimar. Por ejemplo, puede ser que tengamos una moneda posiblemente trucada, la hayamos lanzado 100 veces al aire y hayamos anotado los resultados (1, cara, 0, cruz), y a partir de este expermiento queramos estimar la probabilidad de sacar cara con esta moneda. O que hayamos anotado para 100 individuos de una población elegidos al azar si tienen o no una determinada enfermedad (1 significa que sí, 0 que no) y a partir de esta muestra deseemos estimar la prevalencia de la enfermedad en la población, es decir, la proporción real de enfermos, que coincide con la probabilidad de que un individuo elegido al azar tenga dicha enfermedad. Tomemos, para fijar ideas, la siguiente muestra de tamaño 100: x=c(0,1,1,1,0,0,0,0,0,0,0,0,1,1,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,1,0,1,0,0,0, 0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0, 1,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0) En este caso, podemos estimar \\(p\\) mediante la media muestral, que coincide con la proporción muestral \\(\\widehat{p}\\) de éxitos. El error típico de este estimador es \\(\\sqrt{p(1-p)/n}\\), y el error típico de una estimación concreta es \\(\\sqrt{\\widehat{p}(1-\\widehat{p})/n}\\). Por lo tanto, a mano podemos estimar \\(p\\) y calcular el error típico de dicha estimación de la manera siguiente: n=length(x) #Tamaño de la muestra estim.p=mean(x) #Proporción muestral estim.p ## [1] 0.22 error.tip.p=sqrt(estim.p*(1-estim.p)/n) #Error típico de la estimación error.tip.p ## [1] 0.04142463 De esta manera, estimamos que \\(p\\)=0.22 con un error típico de 0.04. Con R podemos estimar un parámetro de una distribución por el método de máxima verosimilitud a partir de una muestra y además obtener el error típico de dicha estimación usando la función fitdistr del paquete MASS. Esta función calcula los estimadores máximo verosímiles de los parámetros de la mayoría de las familias de distribuciones disponibles en R. Su sintaxis básica es fitdistr(x, densfun=&quot;distribución&quot;, start=...) donde x es la muestra, un vector numérico. distribución es el nombre de la familia de distribuciones; se tiene que entrar entre comillas y puede tomar, entre otros, los valores siguientes: &quot;chi-squared&quot;, &quot;exponential&quot;, &quot;f&quot;, &quot;geometric&quot;, &quot;lognormal&quot;, &quot;normal&quot; y &quot;poisson&quot;. La lista de distribuciones a las que se puede aplicar, que podéis consultar en la Ayuda de la función, no incluye la Bernoulli ni la binomial. Si fitdistr no dispone de una fórmula cerrada para el estimador máximo verosímil de algún parámetro, usa un algoritmo numérico para aproximarlo que requiere de un valor inicial para arrancar. Este valor (o valores) se puede especificar igualando el parámetro start a una list con cada parámetro a estimar igualado a un valor inicial. Para algunas distribuciones, como la &quot;t&quot;, fitdistr sabe tomar valores iniciales razonables, y no es necesario especificar el parámetro start. Pero para otras distribuciones, como por ejemplo la &quot;chi-squared&quot;, es obligatorio especificarlo. Para las distribuciones que disponen de fórmula cerrada, como la &quot;normal&quot; o la &quot;poisson&quot;, se tiene que omitir el parámetro start. Como no podemos usar fitdistr para estimar el parámetro \\(p\\) de una Bernoulli (los autores del paquete debieron de considerar que era más fácil estimarlo directamente), vamos a usarla en otro ejemplo. Consideremos la siguiente muestra y de 100 valores generados con distribución de Poisson de parámetro \\(\\lambda=10\\): set.seed(100) y=rpois(100,10) set.seed(NULL) y ## [1] 8 10 9 12 10 11 8 12 7 11 11 12 7 10 9 8 11 7 6 12 10 12 7 ## [24] 7 10 6 7 15 9 9 7 8 15 11 12 5 14 4 7 14 8 14 10 4 9 8 ## [47] 11 11 10 12 7 14 7 9 10 3 10 7 9 21 14 6 13 3 10 6 3 13 9 ## [70] 12 8 11 10 11 11 8 6 17 7 8 10 12 15 12 13 10 9 12 8 11 12 4 ## [93] 10 8 5 8 8 10 8 11 Vamos a estimar el parámetro \\(\\lambda\\) de una distribución Poisson que haya generado este vector: library(MASS) fitdistr(y, densfun=&quot;poisson&quot;) ## lambda ## 9.5600000 ## (0.3091925) El resultado dice que el valor estimado de \\(\\lambda\\) es 9.56, con un error típico en esta estimación de 0.31. Veámoslo directamente: el estimador máximo verosímil de \\(\\lambda\\) es la media aritmética \\(\\overline{X}\\) y el error típico de esta estimación es \\(\\sqrt{\\overline{X}}/\\sqrt{n}\\) (recordad que la desviación típica de una Poisson de parámetro \\(\\lambda\\) es \\(\\sqrt{\\lambda}\\) y que el error típico de la media muestral es la desviación típica poblacional dividida por la raíz cuadrada del tamaño de la muestra). mean(y) ## [1] 9.56 sqrt(mean(y)/length(y)) ## [1] 0.3091925 También podemos estimar la media y la desviación típica de una variable normal que hubiera producido esta muestra. fitdistr(y, densfun=&quot;normal&quot;) ## mean sd ## 9.5600000 3.0832450 ## (0.3083245) (0.2180183) Observad que la estimación de la desviación típica que nos da fitdistr es la desviación típica “verdadera” (que es su estimador máximo verosímil) y no la muestral: sd(y) ## [1] 3.098778 sqrt((length(y)-1)/length(y))*sd(y) ## [1] 3.083245 Vamos a estimar ahora el número de grados de libertad de una t de Student que hubiera producido esta muestra. fitdistr(y, densfun=&quot;t&quot;) ## m s df ## 9.5085516 2.7517475 9.9229027 ## (0.2997949) (0.3072053) (8.4890355) ¡Vaya!, a parte del número de grados de libertad, df, han aparecido parámetros que no esperábamos. Los parámetros m y s son los parámetros de posición, \\(\\mu\\), y de escala, \\(\\sigma\\), respectivamente, que definen una familia más general de distribuciones t de Student (si os interesa, consultad esta entrada de la Wikipedia), Las que usamos en este curso tienen \\(\\mu=0\\) y \\(\\sigma=1\\). ¿Cómo podríamos estimar los grados de libertad de una t de Student de las nuestras? Especificando dentro de fitdistr los valores de los parámetros que queremos que tomen un valor concreto: en este caso, añadiendo m=0 y s=1. fitdistr(y, densfun=&quot;t&quot;, m=0, s=1) ## Error in fitdistr(y, densfun = &quot;t&quot;, m = 0, s = 1): &#39;start&#39; must be a named list Ahora R nos pide que demos un valor inicial al número de grados de libertad, df, para poder arrancar el algoritmo numérico que usará. Vamos a inicializarlo a 1, y de paso veremos cómo se usa este parámetro: fitdistr(y, densfun=&quot;t&quot;,m=0,s=1,start=list(df=1)) ## Warning in stats::optim(x = c(8L, 10L, 9L, 12L, 10L, 11L, 8L, 12L, 7L, 11L, : one-dimensional optimization by Nelder-Mead is unreliable: ## use &quot;Brent&quot; or optimize() directly ## Warning in dt((x - m)/s, df, log = TRUE): NaNs produced ## df ## 0.37265625 ## (0.04277075) Obtenemos un número estimado de grados de libertad de la t de Student de aproximadamente 0.37 grados de libertad (sí, los grados de libertad de una t de Student pueden ser un número real positivo cualquiera). Por otro lado, R nos avisa de que el resultado es poco de fiar, pero tampoco nos importa mucho, porque el objetivo era mostrar un ejemplo de cómo fijar valores de parámetros, igualándolos a dichos valores, y cómo especificar el parámetro start, como una list donde asignamos a cada parámetro un valor inicial. El resultado de fitdistr es una list, y por lo tanto el valor de cada estimador y su error típico se pueden obtener con los sufijos adecuados. En concreto, los valores estimados forman la componente estimate y los errores típicos la componente sd. Para obtenerlos directamente, basta usar los sufijos $estimate y $sd, respectivamente: fitdistr(y,&quot;poisson&quot;)$estimate #Estimación de lambda ## lambda ## 9.56 fitdistr(y,&quot;poisson&quot;)$sd #Error típico ## lambda ## 0.3091925 fitdistr(y,&quot;normal&quot;)$estimate #Estimaciones ## mean sd ## 9.560000 3.083245 fitdistr(y,&quot;normal&quot;)$estimate[1] #Estimación de mu ## mean ## 9.56 fitdistr(y,&quot;normal&quot;)$estimate[2] #Estimación de sigma ## sd ## 3.083245 3.2 Guía rápida fitdistr, del paquete MASS, sirve para calcular los estimadores máximo verosímiles de los parámetros de una distribución a partir de una muestra. El resultado es una list que incluye los objetos estimate (los valores estimados) y sd (los errores típicos de las estimaciones). Sus parámetros principales son: densfun: el nombre de la familia de distribuciones, entre comillas. start: permite fijar el valor inicial del algoritmo numérico para calcular el estimador, si la función lo requiere. 3.3 Ejercicios Modelo de test (1) Las distribuciones de Weibull tienen dos parámetros, forma, shape, y escala, scale. Supongamos que los datos siguientes siguen una distribución de Weibull: 2.46, 2.28, 1.7, 0.62, 0.87, 2.81, 2.35, 2.08, 2.11, 1.72. Calculad el estimador máximo verosímil del parámetro de escala de esta distribución, redondeado a 3 cifras decimales. Tenéis que dar el resultado (sin ceros innecesarios a la derecha), no cómo lo habéis calculado. (2) Generad, con semilla de aleatoriedad igual a 42, una secuencia aleatoria de 100 valores con distribución geométrica \\(Ge(0.6)\\). A continuación estimad el parámetro \\(p\\) de una distribución geométrica que haya generado dicha muestra y dad como respuesta a esta pregunta el error típico de esta estimación redondeado a 3 cifras decimales. Tenéis que dar el resultado (sin ceros innecesarios a la derecha), no cómo lo habéis calculado. Respuestas al test (1) 2.116 Podemos obtener la respuesta con x=c(2.46, 2.28, 1.7, 0.62, 0.87, 2.81, 2.35, 2.08, 2.11, 1.72) round(fitdistr(x,&quot;weibull&quot;)$estimate,3) ## shape scale ## 3.432 2.116 (2) 0.038 Podemos obtener la respuesta con set.seed(42) x=rgeom(100,0.6) round(fitdistr(x,&quot;geometric&quot;)$sd,3) ## prob ## 0.038 "],
["chap-IC.html", "Lección 4 Intervalos de confianza 4.1 Intervalo de confianza para la media basado en la t de Student 4.2 Intervalos de confianza para la proporción poblacional 4.3 Intervalo de confianza para la varianza de una población normal 4.4 Bootstrap 4.5 Guía rápida 4.6 Ejercicios", " Lección 4 Intervalos de confianza En esta lección explicamos cómo calcular con R algunos intervalos de confianza básicos. Recordad que un intervalo de confianza del \\(q\\times 100\\%\\) (con \\(q\\) entre 0 y 1) para un parámetro poblacional (la media, la desviación típica, la proporción poblacional de una variable Bernoulli, …) es un intervalo obtenido aplicando a una muestra una fórmula que garantiza (si se cumplen una serie de condiciones necesarias sobre la distribución de la variable aleatoria poblacional que en cada caso dependen del parámetro y de la fórmula) que el \\(q\\times 100\\%\\) de las veces que la aplicásemos a una muestra aleatoria simple de la misma población, el intervalo resultante contendría el parámetro poblacional. Esto es lo que significa lo de “confianza del \\(q\\times 100\\%\\)”: que suponemos que nuestra muestra es aleatoria simple y confiamos en que pertenece al \\(q\\times 100\\%\\) de las ocasiones en las que la fórmula acierta y da un intervalo que contiene el parámetro deseado. Algunas de las funciones que aparecen en esta lección volverán a salir en la próxima, ya que aunque calculan intervalos de confianza, su función principal es en realidad efectuar contrastes de hipótesis. 4.1 Intervalo de confianza para la media basado en la t de Student Supongamos que queremos estimar a partir de una m.a.s. la media \\(\\mu\\) de una población que sigue una distribución normal o tomando la muestra grande (por fijar una cota, de tamaño 40 o mayor). En esta situación, si \\(\\overline{X}\\), \\(\\widetilde{S}_{X}\\) y \\(n\\) son, respectivamente, la media muestral, la desviación típica muestral y el tamaño de la muestra, un intervalo de confianza del \\(q\\times 100\\%\\) para \\(\\mu\\) es \\[\\begin{equation} \\overline{X}\\pm t_{n-1,(1+q)/2} \\cdot \\frac{\\widetilde{S}_{X}}{\\sqrt{n}} \\tag{4.1} \\end{equation}\\] donde \\(t_{n-1,(1+q)/2}\\) es el cuantil de orden \\((1+q)/2\\) de una variable aleatoria con distribución t de Student con \\(n-1\\) grados de libertad. A la hora de calcular este intervalo de confianza, tenemos dos posibles situaciones. Una, típica de ejercicios, es cuando de la muestra sólo conocemos su media muestral \\(\\overline{x}\\), su desviación típica muestral \\(\\widetilde{s}_x\\) y su tamaño \\(n\\). Si los denotamos por x.b, sdm y n, respectivamente, y denotamos el nivel de confianza en tanto por uno \\(q\\) por conf.level, podemos calcular los extremos de este intervalo de confianza con la expresión siguiente: x.b+(qt((1+conf.level)/2,n-1)*sdm/sqrt(n))*c(-1,1) Ahora bien, “en la vida real” lo usual es disponer de un vector numérico X con los valores de la muestra. En este caso, podemos usar la función t.test de R, que, entre otra información, calcula estos intervalos de confianza para \\(\\mu\\). Si solo nos interesa el intervalo de confianza, podemos usar la sintaxis siguiente: t.test(X,conf.level=...)$conf.int donde tenemos que igualar el parámetro conf.level al nivel de confianza \\(q\\) en tanto por uno. Si \\(q=0.95\\), no hace falta entrarlo, porque es su valor por defecto. Ejemplo 4.1 Tenemos una muestra de pesos, en gramos, de 28 recién nacidos con luxación severa de cadera: pesos=c(2466,3941,2807,3118,3175,3515,3317,3742,3062,3033,2353,3515,3260,2892, 4423,3572,2750,3459,3374,3062,3205,2608,3118,2637,3438,2722,2863,3513) Vamos a suponer que nuestra muestra es aleatoria simple y que los pesos al nacer de los bebés con esta patología siguen una distribución normal. A partir de esta muestra, queremos calcular un intervalo de confianza del 95% para el peso medio de un recién nacido con luxación severa de cadera, y ver si contiene el peso medio de la población global de recién nacidos, que es de unos 3400 g. Como suponemos que la variable aleatoria poblacional es normal, para calcular un intervalo de confianza del 95% para su valor medio podemos usar la fórmula basada en la distribución t de Student, y por lo tanto la función t.test: t.test(pesos)$conf.int ## [1] 2997.849 3355.008 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 El intervalo que obtenemos es (2997.8, 3355) y está completamente a la izquierda del peso medio global de 3400 g, por lo que tenemos evidencia (a un 95% de confianza) de que los niños con luxación severa de cadera tienen menor peso al nacer que la media. La apostilla entre paréntesis “a un 95% de confianza” aquí significa que hemos basado esta conclusión en un intervalo obtenido con una fórmula que acierta con una probabilidad del 95%, en el sentido de que el 95% de las ocasiones que aplicamos esta fórmula a una m.a.s. de una variable aleatoria normal, produce un intervalo que contiene la media de esta variable. Observad que el resultado de t.test(pesos)$conf.int tiene un atributo, conf.level, que indica su nivel de confianza. En principio este atributo no molesta para nada en cálculos posteriores con los extremos de este intervalo de confianza, pero si os molesta, lo podéis quitar igualándolo a NULL. IC.lux=t.test(pesos)$conf.int attr(IC.lux,&quot;conf.level&quot;)=NULL IC.lux ## [1] 2997.849 3355.008 Veamos cómo podríamos haber obtenido este intervalo directamente con la fórmula (4.1) x=mean(pesos) sdm=sd(pesos) n=length(pesos) conf.level=0.95 x+(qt((1+conf.level)/2,n-1)*sdm/sqrt(n))*c(-1,1) ## [1] 2997.849 3355.008 Como podéis ver, coincide con el intervalo obtenido con la función t.test. 4.2 Intervalos de confianza para la proporción poblacional En esta sección consideramos el caso en que la población objeto de estudio sigue una distribución Bernoulli y queremos estimar su probabilidad de éxito (o proporción poblacional) \\(p\\). Para ello, tomamos una muestra aleatoria simple de tamaño \\(n\\) y número de éxitos \\(x\\), y, por lo tanto, de proporción muestral de éxitos \\(\\widehat{p}_X=x/n\\). El método “exacto” de Clopper-Pearson para calcular un intervalo de confianza del \\(q\\times 100\\%\\) para \\(p\\) se basa en el hecho de que, en estas condiciones, el valor de \\(x\\) sigue una distribución binomial \\(B(n,p)\\). Este método se puede usar siempre, sin ninguna restricción sobre la muestra, y consiste básicamente en encontrar los valores \\(p_0,p_1\\) tales que \\[ \\sum_{k=x}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}=(1-q)/2,\\qquad \\displaystyle\\sum_{k=0}^x\\binom{n}{k}p_1^k(1-p_1)^{n-k}=(1-q)/2 \\] y dar el intervalo \\((p_0,p_1)\\). Para calcular este intervalo se puede usar la función binom.exact del paquete epitools. Su sintaxis es binom.exact(x,n,conf.level) donde x y n representan, respectivamente, el número de éxitos y el tamaño de la muestra, y conf.level es \\(q\\), el nivel de confianza en tanto por uno. El valor por defecto de conf.level es 0.95. Ejemplo 4.2 Supongamos que, de una muestra de 15 enfermos tratados con un cierto medicamento, 1 ha desarrollado taquicardia. Queremos conocer un intervalo de confianza del 95% para la proporción de enfermos tratados con este medicamento que presentan este efecto adverso. Tenemos una población Bernoulli, formada por los enfermos tratados con el medicamento en cuestión, donde los éxitos son los enfermos que desarrollan taquicardia. La fracción de éstos es la fracción poblacional \\(p\\) para la que queremos calcular el intervalo de confianza del 95%. Para ello cargamos el paquete epitools y usamos binom.exact: library(epitools) binom.exact(1,15) ## x n proportion lower upper conf.level ## 1 1 15 0.06666667 0.00168643 0.3194846 0.95 El resultado de la función binom.exact es un data frame; el intervalo de confianza deseado está formado por los números en las columnas lower (extremo inferior) y upper (extremo superior): binom.exact(1,15)$lower ## [1] 0.00168643 binom.exact(1,15)$upper ## [1] 0.3194846 Hemos obtenido el intervalo de confianza (0.002,0.319): podemos afirmar con un nivel de confianza del 95% que el porcentaje de enfermos tratados con este medicamento que presentan este efecto adverso está entre el 0.2% y el 31.9%. Supongamos ahora que el tamaño \\(n\\) de la muestra aleatoria simple es grande; de nuevo, pongamos, \\(n\\geq 40\\). En esta situación, podemos usar el Método de Wilson para aproximar, a partir del Teorema Central del Límite, un intervalo de confianza del parámetro \\(p\\) al nivel de confianza \\(q\\times 100\\%\\), mediante la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/2}^2}{2n}\\pm z_{(1+q)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/2}^2}{4n^2}}}{1+\\frac{z_{(1+q)/2}^2}{n}} \\] donde \\(z_{(1+q)/2}\\) es el cuantil de orden \\((1+q)/2\\) de una variable aleatoria normal estándar. Para calcular este intervalo se puede usar la función binom.wilson del paquete epitools. Su sintaxis es binom.wilson(x,n,conf.level) con los mismos parámetros que binom.exact. Ejemplo 4.3 Supongamos que tratamos 45 ratones con un agente químico, y 10 de ellos desarrollan un determinado cáncer de piel. Queremos calcular un intervalo de confianza al 90% para la proporción \\(p\\) de ratones que desarrollan este cáncer de piel al ser tratados con este agente químico. Como 45 es relativamente grande, usaremos el método de Wilson. Para comparar los resultados, usaremos también el método exacto. Fijaos que, en este ejemplo, \\(q=0.9\\). binom.wilson(10,45,0.9) ## x n proportion lower upper conf.level ## 1 10 45 0.2222222 0.1377238 0.3382281 0.9 binom.exact(10,45,0.9) ## x n proportion lower upper conf.level ## 1 10 45 0.2222222 0.1258186 0.3477285 0.9 Con el método de Wilson obtenemos el intervalo (0.138,0.338) y con el método de Clopper-Pearson, el intervalo (0.126,0.348), un poco más ancho: hay una diferencia en los extremos de alrededor de un punto porcentual. Supongamos finalmente que la muestra aleatoria simple es considerablemente más grande que la usada en el método de Wilson y que, además, la proporción muestral de éxitos \\(\\widehat{p}_{X}\\) está alejada de 0 y de 1. Una posible manera de formalizar estas condiciones es requerir que \\(n\\geq 100\\) y que \\(n\\widehat{p}_{X}\\geq 10\\) y \\(n(1-\\widehat{p}_{X})\\geq 10\\); observaréis que estas dos últimas condiciones son equivalentes a que tanto el número de éxitos como el número de fracasos en la muestra sean como mínimo 10. En este caso, se puede usar la fórmula de Laplace, que simplifica la de Wilson (aunque, en realidad, la precede en más de 100 años): un intervalo de confianza del parámetro \\(p\\) al nivel de confianza \\(q\\times 100\\%\\) viene dado aproximadamente por la fórmula \\[ \\widehat{p}_{X}\\pm z_{(1+q)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula está implementada en la función binom.approx del paquete epitools, de uso similar al de las dos funciones anteriores. Ejemplo 4.4 En una muestra aleatoria de 500 familias con niños en edad escolar de una determinada ciudad se ha observado que 340 introducen fruta de forma diaria en la dieta de sus hijos. A partir de este dato, queremos encontrar un intervalo de confianza del 95% para la proporción real de familias de esta ciudad con niños en edad escolar que incorporan fruta fresca de forma diaria en la dieta de sus hijos. Tenemos una población Bernoulli donde los éxitos son las familias que aportan fruta de forma diaria a la dieta de sus hijos, y la fracción de estas familias en el total de la población es la proporción poblacional \\(p\\) para la que queremos calcular el intervalo de confianza. Como \\(n\\) es muy grande y los números de éxitos y fracasos también lo son, podemos emplear el método de Laplace. binom.approx(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.6391123 0.7208877 0.95 Por lo tanto, según la fórmula de Laplace, un intervalo de confianza al 95% para la proporción poblacional es (0.639,0.721). ¿Qué hubiéramos obtenido con los otros dos métodos? binom.wilson(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637873 0.7193822 0.95 binom.exact(340,500) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.6371369 0.7207188 0.95 Como podéis ver, los resultados son muy parecidos, con diferencias de unas pocas milésimas. 4.3 Intervalo de confianza para la varianza de una población normal Supongamos ahora que queremos estimar la varianza \\(\\sigma^2\\), o la desviación típica \\(\\sigma\\), de una población que sigue una distribución normal. Tomamos una muestra aleatoria simple de tamaño \\(n\\), y sea \\(\\widetilde{S}_{X}\\) su desviación típica muestral. En esta situación, un intervalo de confianza del \\(q\\times 100\\%\\) para \\(\\sigma^2\\) es \\[ \\left( \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2},\\ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2}\\right), \\] donde \\(\\chi_{n-1,(1-q)/2}^2\\) y \\(\\chi_{n-1,(1+q)/2}^2\\) son, respectivamente, los cuantiles de orden \\((1-q)/2\\) y \\((1+q)/2\\) de una variable aleatoria que sigue una distribución \\(\\chi^2\\) con \\(n-1\\) grados de libertad. Si conocéis la varianza muestral \\(\\widetilde{S}_{X}^2\\), que denotaremos por varm, podéis calcular este intervalo con la fórmula c((n-1)*varm/qchisq((1+q)/2,n-1),(n-1)*varm/qchisq((1-q)/2,n-1)) Si, en cambio, disponéis de la muestra, podéis calcular este intervalo de confianza con la función varTest del paquete EnvStats. La sintaxis es similar a la usada con t.test: varTest(X,conf.level)$conf.int donde X es el vector que contiene la muestra y conf.level el nivel de confianza, que por defecto es igual a 0.95. Ejemplo 4.5 Un índice de calidad de un reactivo químico es el tiempo que tarda en actuar. Se supone que la distribución de este tiempo de actuación del reactivo es aproximadamente normal. Se realizaron 30 pruebas independientes, que forman una muestra aleatoria simple, en las que se midió el tiempo de actuación del reactivo. Los tiempos obtenidos fueron reactivo = c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19,25,25,26,27,30,33,34,35,40,40,51,51,58,59,83) Queremos usar estos datos para calcular un intervalo de confianza del 95% para la desviación típica de este tiempo de actuación. El siguiente código calcula un intervalo de confianza al 95% para la varianza a partir del vector reactivo: library(EnvStats) varTest(reactivo)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Como la desviación típica es la raíz cuadrada de la varianza, para obtener un intervalo de confianza al 95% para la desviación típica, tenemos que tomar la raíz cuadrada de este intervalo para la varianza: sqrt(varTest(reactivo)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Por lo tanto un intervalo de confianza del 95% para la desviación típica poblacional es (13.83, 23.34). De nuevo, si os molesta, podéis eliminar el atributo conf.level igualándolo a NULL. 4.4 Bootstrap Cuando no tiene sentido usar un método paramétrico como los explicados en las secciones anteriores para calcular un intervalo de confianza porque no se satisfacen las condiciones teóricas que garantizan que el intervalo obtenido contiene el 95% de las veces el parámetro poblacional deseado, podemos recurrir a un método no paramétrico. El más utilizado es el bootstrap, que básicamente consiste en tomar muchas (miles) muestras aleatorias simples de la muestra de la que disponemos, cada una de ellas del mismo tamaño que la muestra original (pero simples, es decir, con reposición), calcular el estimador sobre cada una de estas submuestras, organizar los resultados en un vector, y usar este vector para calcular un intervalo de confianza. La manera más sencilla de llevar a cabo el cálculo final del intervalo de confianza es el llamado método de los percentiles, en el que se toman como extremos del intervalo de confianza del \\(q\\times 100\\%\\) los cuantiles de orden \\((1-q)/2\\) y \\((1+q)/2\\) del vector de estimadores, pero hay mucho otros métodos; encontraréis algunos en la correspondiente entrada de la Wikipedia. Ejemplo 4.6 Volvamos a la muestra de pesos del Ejemplo 4.1, pero supongamos ahora que la variable aleatoria poblacional de la que la hemos extraído no es normal (o que no queremos suponer que lo sea). Vamos a usar el método bootstrap de los percentiles para calcular un intervalo de confianza del 95% para el peso medio poblacional. Para ello, vamos a general 1000 muestras aleatorias simples de la muestra del mismo tamaño que la muestra, calcularemos la media de cada muestra, construiremos un vector con estas medias muestrales, y daremos como extremos del intervalo de confianza los cuantiles de orden 0.025 y 0.975 del vector así obtenido. n=length(pesos) X=replicate(1000,mean(sample(pesos,n,replace=TRUE))) IC.boot=c(quantile(X,0.025),quantile(X,0.975)) round(IC.boot,1) ## 2.5% 97.5% ## 3000.8 3344.6 El intervalo obtenido en este caso es (3000.8, 3344.6); como se trata de un método basado en una simulación aleatoria, seguramente cada ejecución daría un intervalo diferente. Para comparar, recordad que el intervalo de confianza obtenido con la fórmula basada en la t de Student ha sido (2997.8, 3355). El paquete boot dispone de la función boot para llevar a cabo simulaciones bootstrap. Aplicando luego la función boot.ci al resultado de la función boot obtenemos diversos intervalos de confianza basados en el enfoque bootstrap. La sintaxis básica de la función boot es boot(X,estadístico,R) donde: X es el vector que forma la muestra de la que disponemos R es el número de muestras que queremos extraer de la muestra original El estadístico es la función que calcula el estadístico deseado de la submuestra, y tiene que tener dos parámetros: el primero es X, la muestra original, y el segundo el vector de índices de una m.a.s. de X. Por ejemplo, si vamos a usar la función boot para efectuar una simulación bootstrap de medias muestrales, el estadístico sería: media.boot=function(X,índices){mean(X[índices])} Por otro lado, el nivel de confianza se especifica en la función boot.ci mediante el parámetro conf (no conf.level, como hasta ahora), cuyo valor por defecto es, como siempre, 0.95. A modo de ejemplo, vamos a usar las funciones del paquete boot para calcular un intervalo de confianza del 95% para la media de la variable aleatoria que ha producido el vector pesos. library(boot) set.seed(42) simulacion=boot(pesos,media.boot,1000) El resultado simulacion de esta última instrucción es una list que incluye, en su componente t, el vector de 1000 medias muestrales obtenido mediante la simulación; sus 10 primeros valores son: simulacion$t[1:10] ## [1] 3344.571 3107.429 3162.893 3038.857 3094.643 3202.714 3151.250 ## [8] 3020.393 3072.750 3284.750 Calculemos ahora el intervalo de confianza deseado: boot.ci(simulacion) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 1000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = simulacion) ## ## Intervals : ## Level Normal Basic ## 95% (3022, 3345 ) (3021, 3336 ) ## ## Level Percentile BCa ## 95% (3017, 3332 ) (3028, 3359 ) ## Calculations and Intervals on Original Scale Obtenemos cuatro intervalos de confianza para la \\(\\mu\\), calculados con cuatro métodos a partir de la simulación realizada. El intervalo Percentile es el calculado con el método de los percentiles que hemos explicado antes. No vamos a entrar en detalle sobre los métodos que usa para calcular el resto de intervalos, en realidad todos tienen ventajas e inconvenientes. De nuevo, 4.5 Guía rápida t.test(X, conf.level=...)$conf.int calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la media poblacional usando la fórmula basada en la t de Student aplicada a la muestra X. binom.exact(x,n,conf.level=...), del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando el método de Clopper-Pearson a una muestra de tamaño n con x éxitos. binom.wilson(x,n,conf.level=...), del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando el método de Wilson a una muestra de tamaño n con x éxitos. binom.approx(x,n,conf.level=...), del paquete epitools, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la proporción poblacional aplicando la fórmula de Laplace a una muestra de tamaño n con x éxitos. varTest(X,conf.level=...)$conf.int, del paquete EnvStats, calcula el intervalo de confianza del conf.level\\(\\times 100\\%\\) para la varianza poblacional usando la fórmula basada en la khi cuadrado aplicada a la muestra X. boot(X,E,R), del paquete boot, lleva a cabo una simulación bootstrap, tomando R submuestras del vector X y calculando sobre ellas el estadístico representado por E. boot.ci, del paquete boot, aplicado al resultado de una función boot, calcula diversos intervalos de confianza a partir del resultado de la simulación efectuada con boot. El nivel de confianza se especifica con el parámetro conf. 4.6 Ejercicios Modelo de test (a) Tomad la muestra de todas las longitudes de pétalos de flores Iris setosa contenida en la tabla de datos iris y usadla para calcular un intervalo de confianza del 95% para el valor medio de las longitudes de pétalos de esta especie de flores usando la fórmula basada en la t de Student. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 2 cifras decimales (sin ceros innecesarios a la derecha). (b) Tenemos una población de media \\(\\mu\\) desconocida. Tomamos una muestra aleatoria simple de tamaño 80 y obtenemos una media muestral de 6.2 y una desviación típica muestral de 1.2. Usad estos datos y la fórmula del intervalo de confianza para la media basado en la t de Student para calcular un intervalo de confianza al 95% para \\(\\mu\\). Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 2 cifras decimales (sin ceros innecesarios a la derecha). (c) Tenemos una población Bernoulli de proporción poblacional \\(p\\) desconocida. Tomamos una muestra aleatoria simple de 80 individuos y obtenemos una proporción muestral de 35% de éxitos. Calculad un intervalo de confianza para \\(p\\) a un nivel de confianza del 95% usando el método de Wilson. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 3 cifras decimales (sin ceros innecesarios a la derecha). (d) Tomad la muestra de todas las longitudes de pétalos de flores Iris setosa contenida en la tabla de datos iris y usadla para calcular un intervalo de confianza del 95% para la varianza de las longitudes de pétalos de esta especie de flores. Tenéis que dar el extremo inferior y el extremo superior, en este orden, separados por una coma (sin paréntesis u otros delimitadores, ni espacios en blanco) y redondeados a 3 cifras decimales (sin ceros innecesarios a la derecha). Respuestas al test (a) 1.41,1.51 Lo hemos calculado con round(t.test(iris[iris$Species==&quot;setosa&quot;,&quot;Petal.Length&quot;])$conf.int,2) ## [1] 1.41 1.51 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 (b) 5.933,6.467 Lo hemos calculado con x=6.2 n=80 sdm=1.2 conf.level=0.95 round(x+(qt((1+conf.level)/2,n-1)*sdm/sqrt(n))*c(-1,1),2) ## [1] 5.93 6.47 (c) 0.255,0.459 Lo hemos calculado con round(binom.wilson(0.35*80,80),3) ## x n proportion lower upper conf.level ## 1 28 80 0.35 0.255 0.459 0.95 (d) 0.021,0.047 Lo hemos calculado con round(varTest(iris[iris$Species==&quot;setosa&quot;,&quot;Petal.Length&quot;])$conf.int,3) ## LCL UCL ## 0.021 0.047 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 "]
]
