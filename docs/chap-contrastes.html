<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Lección 1 Contrastes de hipótesis | AprendeR: Parte II</title>
  <meta name="description" content="Apuntes AprendeR bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Lección 1 Contrastes de hipótesis | AprendeR: Parte II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apuntes AprendeR bookdown::gitbook." />
  <meta name="github-repo" content="cescrossello/AprendeR-II" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 1 Contrastes de hipótesis | AprendeR: Parte II" />
  
  <meta name="twitter:description" content="Apuntes AprendeR bookdown::gitbook." />
  

<meta name="author" content="The AprendeR team">


<meta name="date" content="2019-01-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">AprendeR: Parte II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#historial"><i class="fa fa-check"></i>Historial</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preguntas"><i class="fa fa-check"></i>Preguntas</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chap-contrastes.html"><a href="chap-contrastes.html"><i class="fa fa-check"></i><b>1</b> Contrastes de hipótesis</a><ul>
<li class="chapter" data-level="1.1" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-medias"><i class="fa fa-check"></i><b>1.1</b> Contrastes para medias</a><ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#el-test-t"><i class="fa fa-check"></i>El test t</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="chap-contrastes.html"><a href="chap-contrastes.html#aqui"><i class="fa fa-check"></i><b>1.2</b> Aquí</a><ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#tests-no-parametricos"><i class="fa fa-check"></i>Tests no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-varianzas"><i class="fa fa-check"></i><b>1.3</b> Contrastes para varianzas</a></li>
<li class="chapter" data-level="1.4" data-path="chap-contrastes.html"><a href="chap-contrastes.html#contrastes-para-proporciones"><i class="fa fa-check"></i><b>1.4</b> Contrastes para proporciones</a></li>
<li class="chapter" data-level="1.5" data-path="chap-contrastes.html"><a href="chap-contrastes.html#calculo-de-la-potencia-de-un-contraste"><i class="fa fa-check"></i><b>1.5</b> Cálculo de la potencia de un contraste</a></li>
<li class="chapter" data-level="1.6" data-path="chap-contrastes.html"><a href="chap-contrastes.html#guia-rapida"><i class="fa fa-check"></i><b>1.6</b> Guía rápida</a></li>
<li class="chapter" data-level="1.7" data-path="chap-contrastes.html"><a href="chap-contrastes.html#ejercicios"><i class="fa fa-check"></i><b>1.7</b> Ejercicios</a><ul>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#ejercicios-1"><i class="fa fa-check"></i>Ejercicios</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#modelo-de-test"><i class="fa fa-check"></i>Modelo de test</a></li>
<li class="chapter" data-level="" data-path="chap-contrastes.html"><a href="chap-contrastes.html#respuestas"><i class="fa fa-check"></i>Respuestas</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/cescrossello/AprendeR-II" target="blank">Publicado con  bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AprendeR: Parte II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:contrastes" class="section level1">
<h1><span class="header-section-number">Lección 1</span> Contrastes de hipótesis</h1>
<p>En esta lección explicamos algunas instrucciones de R que permiten llevar a cabo de manera rápida contrastes de hipótesis sobre parámetros. Antes de empezar, repasemos el vocabulario relacionado con los contrastes de hipótesis:</p>
<ul>
<li><p><strong>Hipótesis nula</strong></p></li>
<li><p><strong>Hipótesis alternativa</strong></p></li>
<li><p><strong>Nivel de significación</strong></p></li>
<li><p><strong>Nivel de confianza</strong></p></li>
<li><p><strong>Intervalo de confianza</strong></p></li>
<li><p><strong>Potencia</strong></p></li>
</ul>
<div id="contrastes-para-medias" class="section level2">
<h2><span class="header-section-number">1.1</span> Contrastes para medias</h2>
<div id="el-test-t" class="section level3 unnumbered">
<h3>El test t</h3>
<p>El <strong>test t</strong> para contrastar una o dos medias basado en la t de Student está implementado en la función <code>t.test</code>. Este test usa diferentes estadísticos según que el contraste sea de una media o de dos; en este último caso, según se usen muestras emparejadas o independientes; y en este último caso, según las poblaciones tengan varianzas iguales o diferentes. Aunque este test solo es exacto (en el sentido de que da la conclusión con el nivel de significación requerido) cuando las poblaciones involucradas siguen distribuciones normales, el Teorema Central del Límite garantiza que también da resultados aproximadamente correctos cuando las muestras son grandes, aunque las poblaciones no sean normales, por lo que en esta situación también se recomienda su uso. En la práctica, el test t se usa como test “de talla única” para contrastar una o dos medias en cualquier situación, pero hay que tener claro que su resultado es fiable tan solo:</p>
<ul>
<li><p>cuando las variables poblacionales involucradas son (aproximadamente) normales, o</p></li>
<li><p>cuando todas las muestras usadas son grandes.</p></li>
</ul>
<p>Al final de esta sección explicamos las funciones asociadas a algunos contrastes no paramétricos que pueden usarse cuando estas condiciones no se cumplen.</p>
<p>La sintaxis básica de la función <code>t.test</code> es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, y, <span class="dt">mu=</span>..., <span class="dt">alternative=</span>..., <span class="dt">conf.level=</span>..., <span class="dt">paired=</span>..., <span class="dt">var.equal=</span>..., <span class="dt">na.omit=</span>...)</code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>x</code> es el vector de datos que forma la muestra que analizamos.</p></li>
<li><p><code>y</code> es un vector opcional; si lo entramos, R entiende que estamos haciendo un contraste de dos medias, con hipótesis nula la igualdad de estas medias.</p></li>
<li><p>Podemos sustituir los vectores <code>x</code> e <code>y</code> por una fórmula <code>variable1~variable2</code> que indique que separamos la variable numérica <code>variable1</code> en dos vectores definidos por los niveles de un factor <code>variable2</code> de dos niveles (o de otra variable asimilable a un factor de dos niveles, como por ejemplo una variable numérica que solo tome dos valores diferentes). Con esta construcción, R entenderá estos vectores como ordenados por el orden natural de los niveles de <code>variable2</code>: <code>x</code> será el vector correspondiente al primer nivel e <code>y</code> el correspondiente al segundo. Hay que tener esto en cuenta a la hora de especificar la hipótesis alternativa si es unilateral. Si las dos variables de la fórmula son columnas de un <em>dataframe</em>, se puede usar el parámetro <code>data=...</code> para indicarlo.</p></li>
<li><p>Solamente tenemos que especificar el parámetro <code>mu</code> si hemos entrado una sola muestra, y en este caso lo hemos de igualar al valor <span class="math inline">\(\mu_0\)</span> que queremos contrastar, de manera que la hipótesis nula será <span class="math inline">\(H_0: \mu=\mu_0\)</span>.</p></li>
<li><p>El parámetro <code>alternative</code> puede tomar tres valores: <code>&quot;two.sided&quot;</code>, para contrastes bilaterales, y <code>&quot;less&quot;</code> y <code>&quot;greater&quot;</code>, para contrastes unilaterales; en esta función, y en todas las que explicamos en esta lección, su valor por defecto, que no hace falta especificar, es <code>&quot;two.sided&quot;</code>. El significado de estos valores depende del tipo de test que efectuemos:</p>
<ul>
<li><p>Si el test es de una sola muestra, <code>&quot;two.sided&quot;</code> representa la hipótesis alternativa <span class="math inline">\(H_1: \mu\neq \mu_0\)</span>, <code>&quot;less&quot;</code> corresponde a <span class="math inline">\(H_1: \mu&lt; \mu_0\)</span>, y <code>&quot;greater&quot;</code> corresponde a <span class="math inline">\(H_1: \mu&gt; \mu_0\)</span>.</p></li>
<li><p>Si hemos entrado dos muestras y llamamos <span class="math inline">\(\mu_x\)</span> y <span class="math inline">\(\mu_y\)</span> a las medias de las poblaciones de las que hemos extraído las muestras <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, respectivamente, entonces <code>&quot;two.sided&quot;</code> representa la hipótesis alternativa <span class="math inline">\(H_1: \mu_x \neq \mu_y\)</span>; <code>&quot;less&quot;</code> indica que la hipótesis alternativa es <span class="math inline">\(H_1: \mu_x&lt; \mu_y\)</span>; y <code>&quot;greater&quot;</code>, que la hipótesis alternativa es <span class="math inline">\(H_1: \mu_x&gt; \mu_y\)</span>.</p></li>
</ul></li>
<li><p>El valor del parámetro <code>conf.level</code> es el nivel de confianza <span class="math inline">\(1-\alpha\)</span>. En esta función, y en todas las que explicamos en esta lección, su valor por defecto, que no es necesario especificar, es 0.95, que corresponde a un nivel de confianza del 95%, es decir, a un nivel de significación <span class="math inline">\(\alpha=0.05\)</span>.</p></li>
<li><p>El parámetro <code>paired</code> solo lo tenemos que especificar si llevamos a cabo un contraste de dos medias. En este caso, con <code>paired=TRUE</code> indicamos que las muestras son emparejadas, y con <code>paired=FALSE</code> (que es su valor por defecto) que son independientes. Si se trata de muestras emparejadas, los vectores <code>x</code> e <code>y</code> tienen que tener la misma longitud, naturalmente.</p></li>
<li><p>El parámetro <code>var.equal</code> solo lo tenemos que especificar si llevamos a cabo un contraste de dos medias de poblaciones independientes, y en este caso sirve para indicar si queremos considerar las dos varianzas iguales (igualándolo a TRUE) o diferentes (igualándolo a FALSE, que es su valor por defecto).</p></li>
<li><p>El parámetro <code>na.action</code> sirve para especificar qué queremos hacer con los valores NA. Es un parámetro genérico que se puede usar en casi todas las funciones de estadística inferencial y análisis de datos. Sus valores más útiles son:</p>
<ul>
<li><p><code>na.omit</code>, su valor por defecto, elimina las entradas NA de los vectores (o los pares que contengan algún NA, en el caso de muestras emparejadas). Por ahora, esta opción por defecto es la adecuada, por lo que no hace falta usar este parámetro, pero conviene saber que hay alternativas.</p></li>
<li><p><code>na.fail</code> hace que la ejecución pare si hay algún NA en los vectores.</p></li>
<li><p><code>na.pass</code> no hace nada con los NA y permite que las operaciones internas de la función sigan su curso y los manejen como les corresponda.</p></li>
</ul></li>
</ul>
<p>La función <code>t.test</code> tiene otros parámetros que se pueden consultar en su Ayuda.</p>
<p>Veamos varios ejemplos de uso de esta función.</p>

<div class="example">
<span id="exm:norm1bis" class="example"><strong>Ejemplo 1.1  </strong></span>Consideremos el siguiente vector de longitud 25:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x=<span class="kw">c</span>(<span class="fl">2.2</span>,<span class="fl">2.66</span>,<span class="fl">2.74</span>,<span class="fl">3.41</span>,<span class="fl">2.46</span>,<span class="fl">2.96</span>,<span class="fl">3.34</span>,<span class="fl">2.16</span>,<span class="fl">2.46</span>,<span class="fl">2.71</span>,<span class="fl">2.04</span>,<span class="fl">3.74</span>,<span class="fl">3.24</span>,<span class="fl">3.92</span>,<span class="fl">2.38</span>,<span class="fl">2.82</span>,<span class="fl">2.2</span>,
<span class="fl">2.42</span>,<span class="fl">2.82</span>,<span class="fl">2.84</span>,<span class="fl">4.22</span>,<span class="fl">3.64</span>,<span class="fl">1.77</span>,<span class="fl">3.44</span>,<span class="fl">1.53</span>)</code></pre></div>
<p>Supongamos que esta muestra ha sido extraída de una población normal. Postulamos que el valor medio <span class="math inline">\(\mu\)</span> de la población no es 2. Para confirmarlo, vamos realizar el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=2\\
H_{1}:\mu\neq 2
\end{array}\right.
\]</span> con nivel de significación <span class="math inline">\(\alpha=0.05\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">2</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 5.912, df = 24, p-value = 4.232e-06
## alternative hypothesis: true mean is not equal to 2
## 95 percent confidence interval:
##  2.523844 3.085756
## sample estimates:
## mean of x 
##    2.8048</code></pre>
<p>(Como los parámetros <code>alternative=&quot;two.sided&quot;</code> y <code>conf.level=0.95</code> eran los que toma R por defecto, en realidad no hacía falta especificarlos.) Observad la información que obtenemos con esta instrucción:</p>
<ul>
<li><p>Información sobre la muestra <span class="math inline">\(x\)</span>: su media muestral (<code>mean of x</code>) <span class="math inline">\(\overline{x}=2.8048\)</span>.</p></li>
<li><p>La hipótesis alternativa (<code>alternative hypothesis</code>), en este caso <code>true mean is not equal to 2</code>: la media verdadera, o poblacional, <span class="math inline">\(\mu\)</span> es diferente de 2.</p></li>
<li><p>El valor <code>t</code> que toma el estadístico <span class="math inline">\(T=\frac{\overline{X}-\mu_0}{\widetilde{S}_X/\sqrt{n}}\)</span> sobre la muestra, en este caso 5.912, y los grados de libertad <code>df</code> (<em>degrees of freedom</em>) de su distribución t de Student cuando la hipótesis nula es verdadera, <code>df = 24</code>.</p></li>
<li><p>El p-valor (<code>p-value</code>) de nuestro test, en este caso <code>p-value = 4.232e-06</code>, es decir, <span class="math inline">\(4.232\times 10^{-6}\)</span>.</p></li>
<li><p>Un intervalo de confianza de nivel <span class="math inline">\(100(1-\alpha)\%\)</span> (en nuestro caso, <code>95 percent confidence interval</code>) para la <span class="math inline">\(\mu\)</span>: en nuestro ejemplo, [2.523844, 3.085756].</p></li>
</ul>
<p>Lo único que no nos dice directamente es si tenemos que rechazar o no la hipótesis nula, pero esto lo deducimos del p-valor: como es más pequeño que el nivel de significación (de hecho, es <em>muy</em> pequeño), podemos rechazar la hipótesis nula, <span class="math inline">\(\mu=2\)</span>, en favor de la alternativa, <span class="math inline">\(\mu \neq 2\)</span>. Es decir, hay evidencia estadísticamente significativa de que <span class="math inline">\(\mu \neq 2\)</span>. Otra manera de decidir si rechazamos o no la hipótesis nula es mirar si el valor que contrastamos pertenece al intervalo de confianza del contraste. Puesto que <span class="math inline">\(2 \notin [2.523844, 3.085756]\)</span>, podemos rechazar la hipótesis nula en favor de la alternativa y concluir que <span class="math inline">\(\mu\neq 2\)</span>.</p>
<p>Repitamos ahora el test cambiando la hipótesis alternativa por <span class="math inline">\(H_{1}:\mu&lt; 3\)</span>, es decir,</p>
<p><span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=3\\
H_{1}:\mu&lt; 3
\end{array}\right.
\]</span> y tomando como nivel de significación <span class="math inline">\(\alpha=0.1\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">3</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.9</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = -1.4339, df = 24, p-value = 0.08225
## alternative hypothesis: true mean is less than 3
## 90 percent confidence interval:
##      -Inf 2.984195
## sample estimates:
## mean of x 
##    2.8048</code></pre>
<p>En este caso, el p-valor es 0.082, por lo que podemos rechazar la hipótesis nula con un nivel de significación del 10% y concluir, con este nivel de significación (es decir, asumiendo esta probabilidad de equivocarnos), que <span class="math inline">\(\mu&lt;3\)</span>; pero fijaos en que con un nivel de significación del 5% no podríamos rechazar la hipótesis nula. El intervalo de confianza es ahora <span class="math inline">\((-\infty,2.984]\)</span> (<code>Inf</code> representa <span class="math inline">\(\infty\)</span>). Que no contenga el 3 (aunque por muy poco) también indica que podemos rechazar la hipótesis nula <span class="math inline">\(\mu=3\)</span> en favor de la alternativa <span class="math inline">\(\mu&lt; 3\)</span>.</p>
<p>El p-valor y el intervalo de confianza se pueden obtener directamente, añadiendo a la instrucción <code>t.test</code> los sufijos <code>$p.value</code> o <code>$conf.int</code>, respectivamente.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">2</span>)<span class="op">$</span>p.value</code></pre></div>
<pre><code>## [1] 4.231586e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">2</span>)<span class="op">$</span>conf.int</code></pre></div>
<pre><code>## [1] 2.523844 3.085756
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">2</span>)<span class="op">$</span>conf.int[<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 2.523844</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(x, <span class="dt">mu=</span><span class="dv">2</span>)<span class="op">$</span>conf.int[<span class="dv">2</span>]</code></pre></div>
<pre><code>## [1] 3.085756</code></pre>
<p>Podéis consultar los sufijos necesarios para obtener las otras componentes del resultado en la Ayuda de la función.</p>

<div class="example">
<span id="exm:colesterol" class="example"><strong>Ejemplo 1.2  </strong></span>Queremos contrastar si el valor medio del nivel de colesterol en una población es de 220 mg/dl o no, a un nivel de significación del 5%. Es decir, si llamamos <span class="math inline">\(\mu\)</span> a la media de la variable aleatoria “Nivel de colesterol de un individuo de esta población, en mg/dl”, queremos realizar el contraste bilateral <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=220\\
H_{1}:\mu \neq 220
\end{array}\right.
\]</span>
</div>

<p>Para ello, hemos tomado una muestra del nivel de colesterol en plasma de 9 individuos de la población. Los datos obtenidos, en mg/dl, son</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">colesterol=<span class="kw">c</span>(<span class="dv">203</span>,<span class="dv">229</span>,<span class="dv">215</span>,<span class="dv">220</span>,<span class="dv">223</span>,<span class="dv">233</span>,<span class="dv">208</span>,<span class="dv">228</span>,<span class="dv">209</span>)</code></pre></div>
<p>Suponemos que el nivel de colesterol en plasma sigue una ley normal. Por lo tanto, nos vamos a fiar del resultado de un test t:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(colesterol, <span class="dt">mu=</span><span class="dv">220</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  colesterol
## t = -0.38009, df = 8, p-value = 0.7138
## alternative hypothesis: true mean is not equal to 220
## 95 percent confidence interval:
##  210.5774 226.7560
## sample estimates:
## mean of x 
##  218.6667</code></pre>
<p>El p-valor es 0.714, muy grande y en particular superior a 0.05, por lo tanto no podemos rechazar la hipótesis nula de que el valor medio sea 220 mg/dl. Además, el intervalo de confianza del 95% del contraste es [210.58, 226.76], y contiene holgadamente el valor 220.</p>
<p>Más adelante en esta misma sección discutiremos qué podemos hacer si el nivel de colesterol en plasma no sigue una ley aproximadamente normal, en cuyo caso el resultado de este test t no sirve para nada.</p>

<div class="example">
<p><span id="exm:iris" class="example"><strong>Ejemplo 1.3  </strong></span>Recordad el <em>dataframe</em> <code>iris</code>, que recoge datos de las flores de 50 ejemplares de cada una de tres especies de iris.</p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(iris)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Queremos estudiar si la longitud media <span class="math inline">\(\mu_v\)</span> de los sépalos de las <em>Iris virginica</em> es mayor que la longitud media <span class="math inline">\(\mu_s\)</span> de los sépalos de las <em>Iris setosa</em> usando las muestras contenidas en esta tabla de datos. Para ello realizamos el contraste</p>
<p><span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_s=\mu_v\\
H_{1}:\mu_s&lt; \mu_v
\end{array}\right.
\]</span> En este caso, se trata de un contraste de dos muestras independientes. Como las muestras son grandes, podemos usar con garantías un test t.</p>
<p>Como no sabemos nada de las varianzas, y no nos supone apenas esfuerzo realizar los tests, llevaremos a cabo el contraste en los dos casos: varianzas iguales y varianzas diferentes.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Más adelante, en el Ejemplo <a href="chap-contrastes.html#exm:variris">1.10</a>, explicamos cómo contrastar si estas varianzas son iguales o diferentes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">S=iris[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;setosa&quot;</span>,]<span class="op">$</span>Sepal.Length
V=iris[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;virginica&quot;</span>,]<span class="op">$</span>Sepal.Length</code></pre></div>
<p>El test suponiendo que las dos varianzas son iguales:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(S, V, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">var.equal=</span><span class="ot">TRUE</span>) </code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  S and V
## t = -15.386, df = 98, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -1.411263
## sample estimates:
## mean of x mean of y 
##     5.006     6.588</code></pre>
<p>El test suponiendo que las dos varianzas son diferentes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(S, V, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">var.equal=</span><span class="ot">FALSE</span>) </code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  S and V
## t = -15.386, df = 76.516, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -1.410804
## sample estimates:
## mean of x mean of y 
##     5.006     6.588</code></pre>
<p>En los dos casos el p-valor es prácticamente 0 y por lo tanto podemos rechazar la hipótesis nula: tenemos evidencia muy significativa de que, en promedio, las flores de la especie setosa tienen sépalos más cortos que las de la especie virginica. El intervalo de confianza del 95% para la diferencia de medias <span class="math inline">\(\mu_s-\mu_v\)</span> en este contraste es en ambos casos <span class="math inline">\((-\infty, -1.41]\)</span> y no contiene el 0, que sería el valor de esta diferencia si la hipótesis nula <span class="math inline">\(\mu_s=\mu_v\)</span> fuera verdad.</p>

<div class="example">
<p><span id="exm:sueño" class="example"><strong>Ejemplo 1.4  </strong></span>En un experimento clásico de la primera década del siglo XX, Student quiso comparar el efecto de dos compuestos químicos, la hiosciamina y la hioscina, sobre el sueño: la hipótesis a contrastar era que la hioscina tiene un mayor efecto somnífero que la hiosciamina. Para contrastarlo, tomó 10 sujetos, midió su promedio de horas de sueño durante períodos de entre 3 y 9 días en condiciones normales, tomando antes de acostarse 0.6 mg de hiosciamina y tomando antes de acostarse 0.6 mg de hioscina, y apuntó para cada sujeto y cada compuesto la diferencia “promedio de horas de sueño tomando el compuesto menos promedio de horas de sueño en condiciones normales”. Las diferencias obtenidas fueron las siguientes:<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
</div>

<table>
<thead>
<tr class="header">
<th align="right">Sujeto</th>
<th align="right">Hiosciamina</th>
<th align="right">Hioscina</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.7</td>
<td align="right">1.9</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">-1.6</td>
<td align="right">0.8</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">-0.2</td>
<td align="right">1.1</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">-1.2</td>
<td align="right">0.1</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">-0.1</td>
<td align="right">-0.1</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">3.4</td>
<td align="right">4.4</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">3.7</td>
<td align="right">5.5</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.8</td>
<td align="right">1.6</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.0</td>
<td align="right">4.6</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">2.0</td>
<td align="right">3.4</td>
</tr>
</tbody>
</table>
<p>Una manera de comparar el efecto en las horas de sueño de estos compuestos es comparando las medias de estas diferencias en promedios de horas de sueño: una diferencia mayor significa que el compuesto “ha añadido” más horas de sueño al promedio normal. Digamos <span class="math inline">\(\mu_1\)</span> a la media de las diferencias individuales del promedio de horas de sueño tomando hiosciamina menos el promedio en condiciones normales y <span class="math inline">\(\mu_2\)</span> a la media de las diferencias individuales del promedio de horas de sueño tomando hioscina menos el promedio en condiciones normales. Tomaremos como hipótesis nula <span class="math inline">\(H_0: \mu_1= \mu_2\)</span> (ambos compuestos tienen el mismo efecto medio sobre las horas de sueño de los individuos) e hipótesis alternativa <span class="math inline">\(H_1: \mu_1&lt;\mu_2\)</span> (la hioscina aumenta más las horas de sueño que la hiosciamina). Si podemos rechazar la hipótesis nula en favor de la alternativa, concluiremos que la hioscina tiene un mayor efecto somnífero que la hiosciamina.</p>
<p>Observad que se trata de un contraste de dos muestras emparejadas, porque los datos refieren a los mismos 10 pacientes. Vamos a suponer que las diferencias medias en horas de sueño en ambos casos siguen leyes normales (Student así lo hizo) y que, por lo tanto, el resultado de un test t es fiable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hiosciamina=<span class="kw">c</span>(<span class="fl">0.7</span>,<span class="op">-</span><span class="fl">1.6</span>,<span class="op">-</span><span class="fl">0.2</span>,<span class="op">-</span><span class="fl">1.2</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">3.4</span>,<span class="fl">3.7</span>,<span class="fl">0.8</span>,<span class="dv">0</span>,<span class="fl">2.0</span>)
Hioscina=<span class="kw">c</span>(<span class="fl">1.9</span>,<span class="fl">0.8</span>,<span class="fl">1.1</span>,<span class="fl">0.1</span>,<span class="op">-</span><span class="fl">0.1</span>,<span class="fl">4.4</span>,<span class="fl">5.5</span>,<span class="fl">1.6</span>,<span class="fl">4.6</span>,<span class="fl">3.4</span>)
<span class="kw">t.test</span>(Hiosciamina, Hioscina, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">paired=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  Hiosciamina and Hioscina
## t = -4.0621, df = 9, p-value = 0.001416
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##        -Inf -0.8669947
## sample estimates:
## mean of the differences 
##                   -1.58</code></pre>
<p>El p-valor es 0.001, mucho menor que 0.05, y por lo tanto podemos rechazar la hipótesis nula con un nivel de significación del 5%. Observad también que el intervalo de confianza del 95% para la diferencia de medias <span class="math inline">\(\mu_1-\mu_2\)</span> es <span class="math inline">\((-\infty,-0.867]\)</span> y está totalmente a la izquierda del 0. La conclusión es, pues, que efectivamente la hioscina tiene un mayor efecto somnífero que la hiosciamina.</p>

<div class="example">
<p><span id="exm:fumar" class="example"><strong>Ejemplo 1.5  </strong></span>Veamos un ejemplo de aplicación de <code>t.test</code> a una fórmula. Queremos contrastar si es cierto que fumar durante el embarazo está asociado a un peso menor del recién nacido. Si llamamos <span class="math inline">\(\mu_n\)</span> y <span class="math inline">\(\mu_f\)</span> al peso medio de un recién nacido de madre no fumadora y fumadora, respectivamente, el contraste que queremos realizar es <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_n=\mu_f\\
H_{1}:\mu_n&gt; \mu_f
\end{array}\right.
\]</span> Vamos a usar los datos incluidos en la tabla de datos <code>birthwt</code> incluida en el paquete <code>MASS</code>, que recoge algunos datos sobre una muestra de madres y sus hijos.</p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">str</span>(birthwt)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    189 obs. of  10 variables:
##  $ low  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ age  : int  19 33 20 21 18 21 22 17 29 26 ...
##  $ lwt  : int  182 155 105 108 107 124 118 103 123 113 ...
##  $ race : int  2 3 1 1 1 3 1 3 1 1 ...
##  $ smoke: int  0 0 1 1 1 0 0 0 1 1 ...
##  $ ptl  : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ ht   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ ui   : int  1 0 0 1 1 0 0 0 0 0 ...
##  $ ftv  : int  0 3 1 2 0 0 1 1 1 0 ...
##  $ bwt  : int  2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 ...</code></pre>
<p>En la Ayuda de <code>birthwt</code> nos enteramos de que la variable <code>smoke</code> indica si la madre ha fumado durante el embarazo (1) o no (0), y que la variable <code>bwt</code> da el peso del recién nacido en gramos. Lo primero que haremos será mirar si las muestras de madres fumadoras y no fumadoras contenidas en esta tabla son lo suficientemente grandes como para que el resultado del test t sea fiable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(birthwt<span class="op">$</span>smoke)</code></pre></div>
<pre><code>## 
##   0   1 
## 115  74</code></pre>
<p>Vemos que sí, que ambas son suficientemente grandes.</p>
<p>Para entrar en la instrucción <code>t.test</code> los vectores de pesos de hijos de fumadoras y no fumadoras, usaremos la fórmula <code>bwt~smoke</code> especificando que <code>data=birthwt</code>. Fijaos en que los valores de <code>smoke</code> son 0 y 1, y que R los considera ordenados en este orden (basta ver el resultado de la función <code>table</code> anterior). Por consiguiente, <code>bwt~smoke</code> representa, en este orden, el vector de pesos de recién nacidos de madres no fumadoras (<code>smoke=0</code>) y el vector de pesos de recién nacidos de madres fumadoras (<code>smoke=1</code>). Como la hipótesis alternativa es <span class="math inline">\(\mu_n&gt;\mu_f\)</span>, deberemos especificar en la función <code>t.test</code> que <code>alternative=&quot;greater&quot;</code>.</p>
<p>Como en el Ejemplo <a href="chap-contrastes.html#exm:iris">1.3</a>, vamos a llevar a cabo el test t suponiendo que las varianzas son iguales y que son diferentes, y cruzaremos los dedos para que la conclusión sea la misma. Otra posibilidad es contrastar antes la igualdad de estas varianzas.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(bwt<span class="op">~</span>smoke, <span class="dt">data=</span>birthwt, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>,<span class="dt">paired=</span><span class="ot">FALSE</span>, <span class="dt">var.equal=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  bwt by smoke
## t = 2.6529, df = 187, p-value = 0.004333
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  106.9528      Inf
## sample estimates:
## mean in group 0 mean in group 1 
##        3055.696        2771.919</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(bwt<span class="op">~</span>smoke, <span class="dt">data=</span>birthwt, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>,<span class="dt">paired=</span><span class="ot">FALSE</span>, <span class="dt">var.equal=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  bwt by smoke
## t = 2.7299, df = 170.1, p-value = 0.003501
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  111.8548      Inf
## sample estimates:
## mean in group 0 mean in group 1 
##        3055.696        2771.919</code></pre>
<p>En ambos casos hemos obtenido un p-valor inferior a 0.05, lo que nos permite concluir que, en efecto, las madres no fumadoras tienen en promedio hijos más grandes que las fumadoras.</p>
<p>En vez de especificar los vectores de pesos con <code>bwt~smoke,data=birthwt</code>, hubiéramos podido usar <code>birthwt$bwt~birthwt$smoke</code>. Por ejemplo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(birthwt<span class="op">$</span>bwt<span class="op">~</span>birthwt<span class="op">$</span>smoke, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>,<span class="dt">paired=</span><span class="ot">FALSE</span>, <span class="dt">var.equal=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  birthwt$bwt by birthwt$smoke
## t = 2.6529, df = 187, p-value = 0.004333
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  106.9528      Inf
## sample estimates:
## mean in group 0 mean in group 1 
##        3055.696        2771.919</code></pre>
</div>
</div>
<div id="aqui" class="section level2">
<h2><span class="header-section-number">1.2</span> Aquí</h2>
<div id="tests-no-parametricos" class="section level3 unnumbered">
<h3>Tests no paramétricos</h3>
<p>Cuando comparamos dos medias, o una media con un valor, usando un test t sobre muestras pequeñas, suponemos que las variables poblacionales que han producido las muestras son normales. En la Lección <a href="#chap:bondad"><strong>??</strong></a> estudiaremos los contrastes que nos permiten aceptar o rechazar que una muestra provenga de una variable aleatoria con una distribución concreta, pero en estos momentos ya tendría que ser claro que nos podemos encontrar con conjuntos de datos para los cuales el supuesto de normalidad de la variable poblacional no esté justificado: por ejemplo, porque sean datos cuantitativos discretos o porque la variable sea claramente muy asimétrica. En las situaciones en las que no estamos seguros de que las variables poblacionales satisfagan aproximadamente las hipótesis de los teoremas que nos garantizan la fiabilidad de las conclusiones de un contraste, por ejemplo de un test t, una salida razonable es usar un <strong>test no paramétrico</strong> alternativo.</p>
<p>En el caso de los contrastes de medias, los tests no paramétricos para comparar medias en realidad lo que comparan son las medianas. Los más populares son los siguientes:</p>
<ul>
<li><p>El <strong>test de signos</strong>, que permite contrastar si la mediana de una variable aleatoria cualquiera (incluso ordinal) es un valor dado <span class="math inline">\(M_0\)</span> estudiando la distribución de los signos de las diferencias entre los valores de una muestra y <span class="math inline">\(M_0\)</span> (si la mediana fuera <span class="math inline">\(M_0\)</span>, los números de diferencias positivas y negativas seguirían distribuciones binomiales con <span class="math inline">\(p=0.5\)</span>). En R está implementado en la función <code>SIGN.test</code> del paquete <code>BSDA</code>. Su sintaxis es similar a la de <code>t.test</code> para una muestra, cambiando el parámetro <code>mu</code>, que en <code>t.test</code> sirve para especificar el valor de la media que contrastamos, por <code>md</code>, que en <code>SIGN.test</code> sirve para especificar el valor de la <strong>mediana</strong> que contrastamos. Esta función también se puede aplicar a dos muestras emparejadas: en este caso, la hipótesis nula del contraste que realiza es que “la mediana de las diferencias de las dos variables es 0”.</p></li>
<li><p>El <strong>test de Wilcoxon</strong> para comparar la media de una variable continua simétrica con un valor dado o las medias de dos variables continuas cuya diferencia sea simétrica por medio de muestras emparejadas. En R está implementado en la función <code>wilcox.test</code> y su sintaxis es la misma que la de <code>t.test</code> para una muestra o para dos muestras emparejadas (en este último caso, hay que especificar <code>paired=TRUE</code>).</p></li>
<li><p>El <strong>test de Mann-Whitney</strong> para comparar las medianas de dos variables aleatorias por medio de muestras independientes. En R también está implementado en la función <code>wilcox.test</code> y su sintaxis es la misma que la de <code>t.test</code> para dos muestras independientes (especificando <code>paired=FALSE</code>), salvo que aquí no hay que especificar si las varianzas son iguales o diferentes, puesto que esto no se usa en este test.</p></li>
</ul>

<div class="example">
<p><span id="exm:wilcox-colesterol" class="example"><strong>Ejemplo 1.6  </strong></span>Si los niveles de colesterol no siguen una distribución normal, el test t realizado en el Ejemplo <a href="chap-contrastes.html#exm:colesterol">1.2</a> no sirve para nada. Una posibilidad es entonces no contrastar si el nivel medio de colesterol es 220, sino si el nivel <em>mediano</em> de colesterol es 220 con un test de signos. Los parámetros <code>alternative=&quot;two.sided&quot;</code> y <code>conf.level=0.95</code> son los que esta función usa por defecto, así que no haría falta especificarlos; los incluimos para que los veáis.</p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(BSDA)
<span class="kw">SIGN.test</span>(colesterol, <span class="dt">md=</span><span class="dv">220</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>## 
##  One-sample Sign-Test
## 
## data:  colesterol
## s = 4, p-value = 1
## alternative hypothesis: true median is not equal to 220
## 95 percent confidence interval:
##  208.0778 228.9222
## sample estimates:
## median of x 
##         220 
## 
## Achieved and Interpolated Confidence Intervals: 
## 
##                   Conf.Level   L.E.pt   U.E.pt
## Lower Achieved CI     0.8203 209.0000 228.0000
## Interpolated CI       0.9500 208.0778 228.9222
## Upper Achieved CI     0.9609 208.0000 229.0000</code></pre>
<p>Observad que la salida de la función es muy similar a la de <code>t.test</code> (salvo por los últimos intervalos de confianza, que no vamos a explicar). El p-valor ha dado directamente 1 y el intervalo de confianza al 95% para la mediana ha dado [208.1, 228.9]: por lo tanto, no podemos rechazar que la mediana del nivel de colesterol en la población de la que hemos extraído la muestra sea 220.</p>
<p>Si supiéramos que el nivel de colesterol en sangre tiene una distribución simétrica (de manera que, en particular, su media y su mediana coincidieran), también podríamos usar el test de Wilcoxon para realizar este contraste:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(colesterol, <span class="dt">mu=</span><span class="dv">220</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,<span class="dt">conf.level=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>## Warning in wilcox.test.default(colesterol, mu = 220, alternative =
## &quot;two.sided&quot;, : cannot compute exact p-value with zeroes</code></pre>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  colesterol
## V = 15, p-value = 0.7263
## alternative hypothesis: true location is not equal to 220</code></pre>
<p>El p-valor es 0.726, la conclusión es la misma. El mensaje de advertencia nos avisa de que la muestra ha contenido valores iguales al valor contrastado de la media, por lo que el p-valor obtenido no es exacto. Solo os tenéis que preocupar de un mensaje como este si el p-valor fuera muy cercano al nivel de significación deseado, que no es el caso.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-26" class="example"><strong>Ejemplo 1.7  </strong></span>Si las diferencias en promedios de horas de sueño no siguen distribuciones normales, el test t realizado en el Ejemplo <a href="chap-contrastes.html#exm:sueño">1.4</a> no sirve para nada. En este caso, vamos a usar un test de Wilcoxon para muestras emparejadas. Este test en realidad contrastará la <em>hipótesis nula</em> de que si para cada individuo calculamos la diferencia entre el aumento promedio de horas de sueño cuando toma hiosciamina y el aumento promedio tomando hioscina, la <strong>mediana</strong> de la variable aleatoria que define estas diferencias es 0, y como hipótesis alternativa que esta mediana es menor que 0. Si las variables “aumento de horas de sueño” en juego son simétricas, estas medianas coinciden con las correspondientes medias y llevamos a cabo el contraste del Ejemplo <a href="chap-contrastes.html#exm:sueño">1.4</a>. Si no son simétricas, igualmente estamos contrastando si la hioscina es más efectiva que la hiosciamina, solo que planteándolo de una manera más enrevesada.</p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(Hiosciamina, Hioscina, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">paired=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Warning in wilcox.test.default(Hiosciamina, Hioscina, alternative =
## &quot;less&quot;, : cannot compute exact p-value with ties</code></pre>
<pre><code>## Warning in wilcox.test.default(Hiosciamina, Hioscina, alternative =
## &quot;less&quot;, : cannot compute exact p-value with zeroes</code></pre>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  Hiosciamina and Hioscina
## V = 0, p-value = 0.004545
## alternative hypothesis: true location shift is less than 0</code></pre>
<p>En este caso R nos avisa de nuevo de que el p-valor no es exacto, pero esto no afecta a la conclusión dado que el p-valor es muy pequeño: rechazamos la hipótesis nula en favor de la alternativa y también concluimos con este test no paramétrico que la hioscina tiene un mayor efecto somnífero que la hiosciamina.</p>

<div class="example">
<span id="exm:unnamed-chunk-28" class="example"><strong>Ejemplo 1.8  </strong></span>Nos preguntamos si los hijos de madres de 20 años tienen el mismo peso medio al nacer que los de madres de 30 años, o no. Vamos a responder esta pregunta con un contraste bilateral de estos pesos medios usando la muestra recogida en la tabla de datos <code>birthwt</code>, que contiene la variable `age} con la edad de las madres.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hijos.<span class="dv">20</span>=birthwt[birthwt<span class="op">$</span>age<span class="op">==</span><span class="dv">20</span>,<span class="st">&quot;bwt&quot;</span>]
hijos.<span class="dv">30</span>=birthwt[birthwt<span class="op">$</span>age<span class="op">==</span><span class="dv">30</span>,<span class="st">&quot;bwt&quot;</span>]
<span class="kw">c</span>(<span class="kw">length</span>(hijos.<span class="dv">20</span>),<span class="kw">length</span>(hijos.<span class="dv">30</span>))</code></pre></div>
<pre><code>## [1] 18  7</code></pre>
<p>Las muestras no son lo suficientemente grandes como para usar un test t si no estamos seguros de que las variables poblacionales sean normales. Como las muestras son independientes, vamos a usar un test de Mann-Whitney para comparar los pesos medianos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(hijos.<span class="dv">20</span>, hijos.<span class="dv">30</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,<span class="dt">paired=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Warning in wilcox.test.default(hijos.20, hijos.30, alternative =
## &quot;two.sided&quot;, : cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  hijos.20 and hijos.30
## W = 43.5, p-value = 0.2501
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>El p-valor es 0.25, por lo que no podemos rechazar que las medianas de los pesos al nacer de los hijos de madres de 20 años y de 30 sean iguales.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
</div>
</div>
<div id="contrastes-para-varianzas" class="section level2">
<h2><span class="header-section-number">1.3</span> Contrastes para varianzas</h2>
<p>El test <span class="math inline">\(\chi^2\)</span> para comparar la varianza <span class="math inline">\(\sigma^2\)</span> (o la desviación típica <span class="math inline">\(\sigma\)</span>) de una población normal con un valor dado <span class="math inline">\(\sigma_0^2\)</span> usa el estadístico <span class="math display">\[
\frac{(n-1)\widetilde{S}_X^2}{\sigma_0^2}
\]</span> que, si la hipótesis nula <span class="math inline">\(\sigma^2=\sigma_0^2\)</span> es verdadera, sigue una distribución <span class="math inline">\(\chi^2_{n-1}\)</span>, de ahí su nombre. Dicho test está convenientemente implementado en la función <code>sigma.test</code> del paquete <strong>TeachingDemos</strong>. Su sintaxis es la misma que la de la función <code>t.test</code> para una muestra, substituyendo el parámetro <code>mu</code> de <code>t.test</code> por el parámetro <code>sigma</code> (para especificar el valor de la desviación típica que contrastamos, <span class="math inline">\(\sigma_0\)</span>) o <code>sigmasq</code> (para especificar el valor de la varianza que contrastamos, <span class="math inline">\(\sigma_0^2\)</span>). Como siempre, los valores por defecto de <code>alternative</code> y <code>conf.level</code> son <code>&quot;two.sided&quot;</code> y 0.95, respectivamente. La salida de la función es también similar a la de <code>t.test</code>. Veamos un ejemplo.</p>

<div class="example">
<span id="exm:unnamed-chunk-31" class="example"><strong>Ejemplo 1.9  </strong></span>Se ha realizado un experimento para estudiar el tiempo <span class="math inline">\(X\)</span> (en minutos) que tarda un lagarto del desierto en llegar a los 45<sup>o</sup> partiendo de su temperatura normal mientras está a la sombra. Los tiempos obtenidos (en minutos) en una muestra aleatoria de lagartos fueron
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TL45=<span class="kw">c</span>(<span class="fl">10.1</span>,<span class="fl">12.5</span>,<span class="fl">12.2</span>,<span class="fl">10.2</span>,<span class="fl">12.8</span>,<span class="fl">12.1</span>,<span class="fl">11.2</span>,<span class="fl">11.4</span>,<span class="fl">10.7</span>,<span class="fl">14.9</span>,<span class="fl">13.9</span>,<span class="fl">13.3</span>)</code></pre></div>
<p>Supongamos que estos tiempos siguen una ley normal. ¿Aporta este experimento evidencia de que la desviación típica <span class="math inline">\(\sigma\)</span> de <span class="math inline">\(X\)</span> es inferior a 1.5 minutos? Para responder esta pregunta, hemos de realizar el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma\geq 1.5 \\
H_{1}:\sigma&lt; 1.5
\end{array}\right.
\]</span> Para ello, usaremos la función <code>sigma.test}</code> aplicada a esta muestra y a <code>sigma=1.5</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(TeachingDemos)
<span class="kw">sigma.test</span>(TL45, <span class="dt">sigma=</span><span class="fl">1.5</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  One sample Chi-squared test for variance
## 
## data:  TL45
## X-squared = 10.689, df = 11, p-value = 0.5303
## alternative hypothesis: true variance is less than 2.25
## 95 percent confidence interval:
##  0.000000 5.256863
## sample estimates:
## var of TL45 
##    2.186288</code></pre>
<p>El p-valor que obtenemos es 0.5303, muy grande, por lo que no tenemos evidencia que nos permita rechazar la hipótesis nula en favor de <span class="math inline">\(\sigma&lt;1.5\)</span>.</p>
<p>El test <span class="math inline">\(\chi^2\)</span> no se usa mucho en la práctica. En parte, porque realmente es poco interesante ya que suele ser difícil conjeturar la desviación típica a contrastar, y en parte porque su validez depende fuertemente de la hipótesis de que la variable aleatoria poblacional sea normal. En cambio, el contraste de las desviaciones típicas de dos poblaciones sí que es muy utilizado. Por ejemplo, en un contraste de dos medias usando dos muestras independientes, nos puede interesar conocer <em>a priori</em> si las varianzas poblacionales son iguales o diferentes, en lugar de realizar el test bajo ambas suposiciones. Si no las conocemos, ¿cómo podemos saber cuál es el caso? Si las dos variables poblacionales son normales, podemos contrastar la igualdad de las varianzas con el <strong>test F</strong>, basado en el estadístico <span class="math display">\[
\frac{\widetilde{S}_{X_1}^2} {\widetilde{S}_{X_2}^2}
\]</span> que, si las dos poblaciones tienen la misma varianza, sigue una distribución F de Fisher-Snedecor. Por desgracia, este test es también muy sensible a la no normalidad de las poblaciones objeto de estudio: a la que una de ellas se aleja un poco de la normalidad, el test deja de dar resultados fiables.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>La función para efectuar este test es <code>var.test</code> y su sintaxis básica es la misma que la de <code>t.test</code> para dos muestras:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var.test</span>(x, y, <span class="dt">alternative=</span>..., <span class="dt">conf.level=</span>...)</code></pre></div>
<p>donde <code>x</code> e <code>y</code> son los dos vectores de datos, que se pueden especificar mediante una fórmula como en el caso de <code>t.test</code>, y el parámetro <code>alternative</code> puede tomar los tres mismos valores que en los tests anteriores: su valor por defecto es, como siempre, <code>&quot;two.sided&quot;</code>, que es el que nos permite contrastar si las varianzas son iguales o diferentes.</p>

<div class="example">
<span id="exm:variris" class="example"><strong>Ejemplo 1.10  </strong></span>Suponiendo que las longitudes de los sépalos de las flores de las diferentes especies de iris siguen leyes normales, ¿hubiéramos podido considerar <em>a priori</em> iguales las varianzas de las dos muestras en el Ejemplo @ref{exm:iris}? Veamos:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">S=iris[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;setosa&quot;</span>,]<span class="op">$</span>Sepal.Length
V=iris[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;virginica&quot;</span>,]<span class="op">$</span>Sepal.Length
<span class="kw">var.test</span>(S,V)</code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  S and V
## F = 0.30729, num df = 49, denom df = 49, p-value = 6.366e-05
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.1743776 0.5414962
## sample estimates:
## ratio of variances 
##          0.3072862</code></pre>
<p>El p-valor es <span class="math inline">\(6.366\cdot 10^{-5}\)</span>, muy pequeño. Por lo tanto, podemos rechazar la hipótesis nula de que las dos varianzas son iguales, en favor de la hipótesis alternativa de que las dos varianzas son diferentes. Así, pues, bastaba realizar solo el <code>t.test</code> con <code>var.equal=FALSE</code>.</p>
<p>Observemos también que <code>var.test</code> nos da el intervalo de confianza al nivel especificado (o al 95% si usamos el nivel de confianza por defecto) para <em>el cociente de las varianzas</em> <span class="math inline">\(\sigma^2_x/\sigma^2_y\)</span>. En este caso, el intervalo de confianza al 95% es <span class="math inline">\([0.174, 0.541]\)</span> y como no contiene el 1, confirma la evidencia de que <span class="math inline">\(\sigma^2_x\neq \sigma^2_y\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-36" class="example"><strong>Ejemplo 1.11  </strong></span>Queremos contrastar si los gatos adultos macho pesan más que los gatos adultos hembra. Para ello usaremos los datos recogidos en el <em>dataframe</em> <code>cats</code> del paquete <strong>MASS</strong>, que contiene información sobre el peso de una muestra de gatos adultos, separados por su sexo.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(cats)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    144 obs. of  3 variables:
##  $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Bwt: num  2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ...
##  $ Hwt: num  7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(cats<span class="op">$</span>Sex)</code></pre></div>
<pre><code>## 
##  F  M 
## 47 97</code></pre>
<p>Consultando la Ayuda de <code>cats</code> nos enteramos de que la variable <code>Bwt</code> contiene el peso de cada gato en kg, y la variable <code>Sex</code> contiene el sexo de cada gato: F para hembra (<em>female</em>) y M para macho (<em>male</em>). Como vemos en la tabla de frecuencias, los números de ejemplares de cada sexo son diferentes y grandes.</p>
<p>Así pues, si llamamos <span class="math inline">\(\mu_m\)</span> al peso medio de un gato macho adulto y <span class="math inline">\(\mu_h\)</span> al peso medio de un gato hembra adulto, el contraste que vamos a realizar es <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_m=\mu_h\\
H_{1}:\mu_m&gt;\mu_h
\end{array}\right.
\]</span> y para ello antes vamos a contrastar si las varianzas de ambas poblaciones son iguales o diferentes, para luego poder aplicar el <code>t.test</code> con el valor de <code>var.equal</code> adecuado. Vamos a suponer que los pesos en ambos sexos siguen leyes normales. Para que el contraste de las varianzas sea fiable es necesario que esta suposición sea cierta; para el de los pesos medios, no, ya que ambas muestras son grandes. El contraste de la igualdad de varianzas es el siguiente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var.test</span>(Bwt<span class="op">~</span>Sex, <span class="dt">data=</span>cats)</code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  Bwt by Sex
## F = 0.3435, num df = 46, denom df = 96, p-value = 0.0001157
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.2126277 0.5803475
## sample estimates:
## ratio of variances 
##          0.3435015</code></pre>
<p>El p-valor es <span class="math inline">\(10^{-5}\)</span>, y por lo tanto podemos rechazar la hipótesis nula de que las varianzas son iguales y concluir que son diferentes. Así que en el test t las consideraremos diferentes.</p>
<p>Recordemos ahora que la hipótesis alternativa que queremos contrastar es <span class="math inline">\(H_{1}:\mu_m&gt;\mu_h\)</span>. En el factor <code>cats$Sex</code>, la F (hembra) va antes que la M (macho), y, por tanto, si entramos los vectores de pesos mediante <code>Bwt~Sex,data=cats</code>, el primer vector corresponderá a las gatas y el segundo a los gatos. Así pues, la hipótesis alternativa que hemos de especificar es que la media del primer vector es inferior a la media del segundo vector: <code>alternative=&quot;less&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(Bwt<span class="op">~</span>Sex, <span class="dt">data=</span>cats, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>,<span class="dt">var.equal=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Bwt by Sex
## t = -8.7095, df = 136.84, p-value = 4.416e-15
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##        -Inf -0.4376663
## sample estimates:
## mean in group F mean in group M 
##        2.359574        2.900000</code></pre>
<p>Como el p-valor es prácticamente 0, podemos concluir que, efectivamente, de media, los gatos macho adultos pesan más que los gatos hembra adultos.</p>
<p>Hemos insistido en que el test F solo es válido si las dos poblaciones cuyas varianzas comparamos son normales. ¿Qué podemos hacer si dudamos de su normalidad? Usar un test no paramétrico que no presuponga esta hipótesis. Hay diversos tests no paramétricos para realizar contrastes bilaterales de dos varianzas. Aquí os recomendamos el <strong>test de Fligner-Killeen</strong>, implementado en la función <code>fligner.test</code>. Se aplica o bien a una <code>list</code> formada por las dos muestras, o bien a una fórmula que separe un vector numérico en dos muestras por medio de un factor de dos niveles.</p>

<div class="example">
<span id="exm:unnamed-chunk-40" class="example"><strong>Ejemplo 1.12  </strong></span>Si queremos contrastar si las varianzas de las longitudes de los sépalos de las flores iris setosa y virginica son iguales o no sin presuponer que siguen leyes normales, podemos usar el test de Fligner-Killeen de la manera siguiente:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fligner.test</span>(<span class="kw">list</span>(S,V))</code></pre></div>
<pre><code>## 
##  Fligner-Killeen test of homogeneity of variances
## 
## data:  list(S, V)
## Fligner-Killeen:med chi-squared = 9.9838, df = 1, p-value =
## 0.001579</code></pre>
<p>El p-valor es <span class="math inline">\(0.0016\)</span>, por lo que podemos concluir que las varianzas son diferentes.</p>

<div class="example">
<span id="exm:unnamed-chunk-42" class="example"><strong>Ejemplo 1.13  </strong></span>Si queremos contrastar si las varianzas de los pesos de los gatos y las gatas adultos son iguales o no sin presuponer que dichos pesos tienen distribuciones normales, podemos usar el test de Fligner-Killeen de la manera siguiente:
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fligner.test</span>(Bwt<span class="op">~</span>Sex, <span class="dt">data=</span>cats)</code></pre></div>
<pre><code>## 
##  Fligner-Killeen test of homogeneity of variances
## 
## data:  Bwt by Sex
## Fligner-Killeen:med chi-squared = 16.909, df = 1, p-value =
## 3.921e-05</code></pre>
<p>El p-valor es <span class="math inline">\(4\cdot 10^{-5}\)</span>, por lo que podemos concluir que las varianzas son diferentes.</p>
</div>
<div id="contrastes-para-proporciones" class="section level2">
<h2><span class="header-section-number">1.4</span> Contrastes para proporciones</h2>
<p>Cuando tenemos que efectuar un contraste sobre una probabilidad de éxito <span class="math inline">\(p\)</span> de una variable Bernoulli, podemos usar el test binomial exacto. Este test usa que, si la hipótesis nula <span class="math inline">\(H_0: p=p_0\)</span> es verdadera, el número de éxitos en una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de la variable sigue una ley binomial <span class="math inline">\(B(n,p_0)\)</span>.<br />
Este test está implementado en la función `binom.test}, cuya sintaxis es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(x, n, <span class="dt">p=</span>..., <span class="dt">alternative=</span>..., <span class="dt">conf.level=</span>...)</code></pre></div>
<p>donde</p>
<ul>
<li><p><code>x</code> y <code>n</code> son números naturales: el número de éxitos y el tamaño de la muestra.</p></li>
<li><p><code>p</code> es la probabilidad de éxito que queremos contrastar</p></li>
<li><p>El significado de <code>alternative</code> y <code>conf.level</code>, y sus posibles valores, son los usuales</p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-45" class="example"><strong>Ejemplo 1.14  </strong></span>En una serie de 5 lanzamientos de una moneda, no he obtenido ninguna cara. ¿Puedo sospechar que la probabilidad de sacar cara es inferior a 0.5? Para decidirlo, si llamo <span class="math inline">\(p\)</span> a la probabilidad de obtener cara con esta moneda, voy a realizar el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p=0.5\\
H_{1}:p&lt; 0.5
\end{array}\right.
\]</span></p>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">p=</span><span class="fl">0.5</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  0 and 5
## number of successes = 0, number of trials = 5, p-value = 0.03125
## alternative hypothesis: true probability of success is less than 0.5
## 95 percent confidence interval:
##  0.0000000 0.4507197
## sample estimates:
## probability of success 
##                      0</code></pre>
<p>El p-valor del test es 0.03125 indica que hay evidencia significativa que permite rechazar la hipótesis nula y concluir que la probabilidad de sacar cara es menor que 0.5. El intervalo de confianza que nos da este test es para la <span class="math inline">\(p\)</span>. En nuestro experimento, nos permite estimar que, a un nivel de confianza del 95%, la probabilidad de sacar cara con nuestra moneda es menor del 45%.</p>
<p>Cuando la muestra es grande, podemos usar también el test aproximado, basado en la aproximación de la distribución de la proporción muestral por medio de una normal dada por el Teorema Central del Límite. En R está implementado en la función <code>prop.test</code>, que sirve además para contrastar dos proporciones por medio de muestras independientes cuando estas son grandes. Su sintaxis es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.test</span>(x, n, <span class="dt">p =</span>..., <span class="dt">alternative=</span>..., <span class="dt">conf.level=</span>...)</code></pre></div>
<p>donde:</p>
<ul>
<li><p><code>x</code> puede ser dos cosas:</p>
<pre><code> *  Un número natural: en este caso, R entiende que es el número de éxitos en una muestra.
 *  Un vector de dos números naturales: en este caso, R entiende que es un contraste de dos proporciones y que estos son los números de éxitos en las muestras.</code></pre></li>
<li><p>Cuando trabajamos con una sola muestra, <code>n</code> es su tamaño. Cuando estamos trabajando con dos muestras, <code>n</code> es el vector de dos entradas de sus tamaños.</p></li>
<li><p>Cuando trabajamos con una sola muestra, <code>p</code> es la proporción poblacional que contrastamos. En el caso de un contraste de dos muestras, no hay que especificarlo.</p></li>
<li><p>El significado de <code>alternative</code> y <code>conf.level</code>, y sus posibles valores, son los usuales.</p></li>
</ul>
<p>Veamos algunos ejemplos.</p>

<div class="example">
<span id="exm:unnamed-chunk-48" class="example"><strong>Ejemplo 1.15  </strong></span>De 50 estudiantes de la UIB encuestados al azar, 3 han sido zurdos. Suponiendo que los estudiantes encuestados formasen una muestra aleatoria simple, ¿aporta esta encuesta evidencia de que la proporción de estudiantes zurdos en la UIB sea inferior al 10%, el porcentaje estimado de zurdos en España? Para decidirlo, y llamando <span class="math inline">\(p\)</span> a la proporción de estudiantes zurdos en la UIB, vamos a realizar el contraste <span class="math display">\[
\left\{
\begin{array}{l}
H_0:p=0.1\\
H_1:p&lt;0.1
\end{array}
\right.
\]</span>
</div>

<p>Como la muestra es grande (<span class="math inline">\(n=50\)</span>) usaremos <code>prop.test</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.test</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dt">p=</span><span class="fl">0.1</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  3 out of 50, null probability 0.1
## X-squared = 0.5, df = 1, p-value = 0.2398
## alternative hypothesis: true p is less than 0.1
## 95 percent confidence interval:
##  0.0000000 0.1539523
## sample estimates:
##    p 
## 0.06</code></pre>
<p>El p-valor obtenido en el test es 0.2398, superior a 0.05, y el intervalo de confianza del 95% para <span class="math inline">\(p\)</span> que hemos obtenido es (0,0.154), que contiene el valor 0.1. Por lo tanto, no podemos rechazar que un 10% de los estudiantes de la UIB sean zurdos.</p>
<p>La conclusión usando el test binomial hubiera sido la misma:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dt">p=</span><span class="fl">0.1</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  3 and 50
## number of successes = 3, number of trials = 50, p-value = 0.2503
## alternative hypothesis: true probability of success is less than 0.1
## 95 percent confidence interval:
##  0.0000000 0.1478372
## sample estimates:
## probability of success 
##                   0.06</code></pre>

<div class="example">
<span id="exm:trampas1" class="example"><strong>Ejemplo 1.16  </strong></span>Una empresa que fabrica trampas para cucarachas ha producido una nueva versión de su trampa más popular y afirma que la nueva trampa mata más cucarachas que la vieja. Hemos llevado a cabo un experimento para comprobarlo. Hemos situado dos trampas en dos habitaciones. En cada habitación hemos soltado 60 cucarachas. La versión vieja de la trampa ha matado 40 y la nueva, 48. ¿Podemos afirmar que la nueva trampa es más efectiva que la vieja?
</div>

<p>Digamos <span class="math inline">\(p_v\)</span> y <span class="math inline">\(p_n\)</span> a las proporciones de cucarachas que matan la trampa vieja y la trampa nueva, respectivamente. La hipótesis nula será que <span class="math inline">\(H_0:p_v=p_n\)</span>, y la hipótesis alternativa <span class="math inline">\(H_1:p_v&lt;p_n\)</span>. Los tamaños de las muestras nos permiten usar `prop.test}.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.test</span>(<span class="kw">c</span>(<span class="dv">40</span>,<span class="dv">48</span>),<span class="kw">c</span>(<span class="dv">60</span>,<span class="dv">60</span>),<span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity
##  correction
## 
## data:  c(40, 48) out of c(60, 60)
## X-squared = 2.0881, df = 1, p-value = 0.07423
## alternative hypothesis: less
## 95 percent confidence interval:
##  -1.00000000  0.01461667
## sample estimates:
##    prop 1    prop 2 
## 0.6666667 0.8000000</code></pre>
<p>El p-valor es 0.07423, y el intervalo de confianza que nos da el test, [-1,0.014617], es para la diferencia de proporciones <span class="math inline">\(p_v-p_n\)</span> y contiene el 0, aunque por poco. En resumen, a un nivel de significación de 0.05 no encontramos evidencia de que la trampa nueva sea mejor que la vieja, pero el resultado no es concluyente y convendría llevar a cabo más experimentos con más cucarachas.</p>
<p>La función <code>prop.test</code> solo sirve para contrastar dos proporciones cuando las dos muestras son independientes y grandes. Un test que se puede usar siempre para contrastar dos proporciones usando muestras independientes es el <strong>test exacto de Fisher</strong>, que usa una distribución hipergeométrica.</p>
<p>Supongamos que evaluamos una característica dicotómica (es decir, que solo puede tomar dos valores y por tanto define distribuciones de Bernoulli) sobre dos poblaciones y tomamos dos muestras independientes, una de cada población. Resumimos los resultados en una tabla como la que sigue: <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Poblaciones}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp;\quad 1 &amp; 2 \\\hline
Característica &amp; Sí &amp;\quad $a$ &amp; $b$ \\
&amp; No &amp;\quad $c$ &amp; $d$
\\\hline
\end{tabular}
\]</span></p>
Llamemos <span class="math inline">\(p_{1}\)</span> a la proporción de individuos con la característica bajo estudio dentro de la población 1 y <span class="math inline">\(p_{2}\)</span> a la proporción de individuos con la característica bajo estudio dentro de la población 2. Queremos contrastar la hipótesis nula <span class="math inline">\(H_{0}:p_1=p_2\)</span> contra alguna hipótesis alternativa. Por ejemplo, en el experimento de las trampas para cucarachas, las poblaciones vendrían definidas por el tipo de trampa, y la característica que tendríamos en cuenta sería si la cucaracha ha muerto o no, lo que nos daría la tabla siguiente:

<p>El test exacto de Fisher está implementado en la función `fisher.test}. Su sintaxis es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(x, <span class="dt">alternative=</span>..., <span class="dt">conf.level=</span>...)</code></pre></div>
<p>donde</p>
<ul>
<li><p><code>x</code> es la matriz <span class="math inline">\(\left(\begin{array}{cc} a &amp; b\\ c &amp; d\end{array}\right)\)</span>, donde los números de éxitos van en la primera fila y los de fracasos en la segunda, y las poblaciones se ordenan por columnas.</p></li>
<li><p>El significado de <code>alternative</code> y <code>conf.level</code>, y sus posibles valores, son los usuales.</p></li>
</ul>
<p>Así, en el ejemplo de las trampas para cucarachas, entraríamos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Datos=<span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">40</span>,<span class="dv">48</span>),<span class="kw">c</span>(<span class="dv">20</span>,<span class="dv">12</span>))
Datos</code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]   40   48
## [2,]   20   12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(Datos, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  Datos
## p-value = 0.07392
## alternative hypothesis: true odds ratio is less than 1
## 95 percent confidence interval:
##  0.000000 1.084135
## sample estimates:
## odds ratio 
##  0.5029092</code></pre>
<p>y obtenemos de nuevo un p-valor cercano a 0.074.</p>
<p>Hay que ir con cuidado con la interpretación del intervalo de confianza que da esta función: no es ni para la diferencia de las proporciones ni para su cociente, sino para su <em>odds ratio</em>: el cociente <span class="math display">\[
\Big({\frac{p_v}{1-p_v}}\Big)\Big/\Big({\frac{p_n}{1-p_n}}\Big)
\]</span></p>
<p>Recordad que si la probabilidad <span class="math inline">\(A\)</span> de un suceso es <span class="math inline">\(P(A)\)</span>, sus <em>odds</em> son el cociente <span class="math display">\[
\mbox{Odds}(A)=\frac{P(A)}{1-P(A)}
\]</span> que mide cuántas veces es más probable <span class="math inline">\(A\)</span> que “no <span class="math inline">\(A\)</span>”. Las <em>odds</em> son una función creciente de la probabilidad, y por lo tanto <span class="math display">\[
\mbox{Odds}(A)&lt;\mbox{Odds}(B)\Longleftrightarrow P(A)&lt;P(B)
\]</span> Esto permite comparar <em>odds</em> en vez de probabilidades, con la misma conclusión. Por ejemplo, en nuestro caso, como el intervalo de confianza para la <em>odds ratio</em> va de 0 a 1.084, en particular contiene el 1, por lo que no podemos rechazar que <span class="math display">\[
\Big({\frac{p_v}{1-p_v}}\Big)\Big/\Big({\frac{p_n}{1-p_n}}\Big)=1
\]</span> es decir, no podemos rechazar que <span class="math display">\[
\frac{p_v}{1-p_v}=\frac{p_n}{1-p_n}
\]</span> y esto es equivalente a <span class="math inline">\(p_v=p_n\)</span>. Si, por ejemplo, el intervalo de confianza hubiera ido de 0 a 0.8, entonces la conclusión a este nivel de confianza hubiera sido que <span class="math display">\[
\Big({\frac{p_v}{1-p_v}}\Big)\Big/\Big({\frac{p_n}{1-p_n}}\Big)&lt;1
\]</span> es decir, que <span class="math display">\[
\frac{p_v}{1-p_v}&lt;\frac{p_n}{1-p_n}
\]</span> y esto es equivalente a <span class="math inline">\(p_v&lt;p_n\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-54" class="example"><strong>Ejemplo 1.17  </strong></span>Para determinar si el Síndrome de Muerte Súbita del Recién Nacido (<em>SIDS</em>, por sus siglas en inglés) tiene algún componente genético, se estudiaron parejas de gemelos y mellizos en las que se dio algún caso de SIDS. Sean <span class="math inline">\(p_1\)</span> la proporción de casos con exactamente una muerte por SIDS entre las parejas de gemelos con algún caso por SIDS, y <span class="math inline">\(p_2\)</span> la proporción de casos con exactamente una muerte por SIDS entre las parejas de mellizos con algún caso de SIDS. La hipótesis de trabajo es que si el SIDS tiene componente genético, será más probable que un gemelo de un muerto por SIDS también lo sufra que si solo es mellizo, y por lo tanto que en las parejas de gemelos ha de ser más raro que haya exactamente un caso de SIDS que en las parejas de mellizos. Es decir, que <span class="math inline">\(p_1&lt;p_2\)</span>. Así pues, queremos realizar el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_0:p_1=p_2\\
H_1:p_1&lt; p_2
\end{array}\right.
\]</span>
</div>

En un estudio de 1980 se obtuvieron los datos siguientes:

<p>Vamos a realizar el contraste. Observad que damos la tabla de manera que <span class="math inline">\(p_1\)</span> es la proporción de parejas con un solo caso de SIDS entre las de la población 1 (gemelos), y <span class="math inline">\(p_{2}\)</span> es la proporción de parejas con un solo caso de SIDS entre las de la población 2 (mellizos). Por tanto hemos de aplicar <code>fisher.test</code> a esta matriz y <span class="math inline">\(p_1&lt;p_2\)</span> corresponderá a <code>alternative=&quot;less&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Datos=<span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">23</span>,<span class="dv">35</span>),<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
Datos</code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]   23   35
## [2,]    1    2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(Datos, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  Datos
## p-value = 0.7841
## alternative hypothesis: true odds ratio is less than 1
## 95 percent confidence interval:
##   0.00000 39.73954
## sample estimates:
## odds ratio 
##   1.308589</code></pre>
<p>El p-valor es 0.7841, muy grande, por lo que no obtenemos evidencia de componente genética en el SIDS.</p>
<p>Las funciones <code>prop.test</code> y <code>fisher.test</code> no pueden usarse para comparar proporciones de muestras emparejadas, en situaciones como la siguiente. Supongamos que evaluamos dos características dicotómicas sobre un mismo conjunto de <span class="math inline">\(n\)</span> individuos y resumimos los resultados en una tabla <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Car. 1}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp; Sí &amp; No \\\hline
Car. 2 &amp; Sí &amp; $a$ &amp; $b$ \\
&amp; No &amp; $c$ &amp; $d$
\\\hline
\end{tabular}
\]</span> donde <span class="math inline">\(a+b+c+d=n\)</span>. Ahora vamos a llamar <span class="math inline">\(p_{1}\)</span> a la proporción de individuos con la característica 1, y <span class="math inline">\(p_{2}\)</span> a la proporción de individuos con la característica 2. Queremos contrastar la hipótesis nula <span class="math inline">\(H_{0}:p_1=p_2\)</span> contra alguna hipótesis alternativa.</p>
<p>En este caso, para realizar el contraste bilateral <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2
\end{array}\right.
\]</span> cuando <span class="math inline">\(n\)</span> es grande y el número <span class="math inline">\(b+c\)</span> de <strong>casos discordantes</strong> (en los que una característica da Sí y la otra da No) es razonablemente grande, pongamos <span class="math inline">\(\geq 20\)</span>, podemos usar el <strong>test de McNemar</strong>, que se lleva a cabo en R con la instrucción <code>mcnemar.test</code>. Su sintaxis básica es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcnemar.test</span>(x)</code></pre></div>
<p>donde <code>x</code> es la matriz <span class="math inline">\(2\times 2\)</span></p>
<p><span class="math display">\[
\left(\begin{array}{cc}
a &amp; b\\ c&amp; d
\end{array}\right)
\]</span> que corresponde a la tabla anterior.</p>

<div class="example">
<span id="exm:asma1" class="example"><strong>Ejemplo 1.18  </strong></span>Para comparar la efectividad de dos tratamientos del asma, se escogieron 200 pacientes con asma severo, y a cada uno se le trató durante un mes con el tratamiento A o el tratamiento B, decidiéndose cada tratamiento al azar; tras esta fase de tratamiento, se les dejó sin tratamiento durante un mes, y a continuación a cada uno se le trató durante un mes con el otro tratamiento (B si antes había recibido A, A si antes había recibido B). Se anotó si durante cada periodo de tratamiento cada enfermo visitó o no el servicio de urgencias por dificultades respiratorias. Los resultados del experimento se resumen en la tabla siguiente: <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Trat. A}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp; Sí &amp; No \\\hline
Trat. B &amp; Sí &amp; $71$ &amp; $48$ \\
&amp; No &amp; $30$ &amp; $51$
\\\hline
\end{tabular}
\]</span>
</div>

<p>Queremos determinar si hay diferencia en la efectividad de los dos tratamientos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Datos=<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">71</span>,<span class="dv">48</span>,<span class="dv">30</span>,<span class="dv">51</span>),<span class="dt">nrow=</span><span class="dv">2</span>,<span class="dt">byrow=</span><span class="ot">TRUE</span>)
Datos</code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]   71   48
## [2,]   30   51</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcnemar.test</span>(Datos)</code></pre></div>
<pre><code>## 
##  McNemar&#39;s Chi-squared test with continuity correction
## 
## data:  Datos
## McNemar&#39;s chi-squared = 3.7051, df = 1, p-value = 0.05425</code></pre>
<p>El p-valor del test es 0.05425, ligeramente superior a 0.05, por lo tanto no permite concluir que haya evidencia de que la efectividad de los dos tratamientos sea diferente. Sería conveniente llevar a cabo un estudio más amplio.</p>
<p>Otra posibilidad para realizar este contraste, que no requiere de ninguna hipótesis sobre los tamaños de las muestras, es usar de manera adecuada el <code>binom.test</code>. Consideremos para ello la tabla siguiente, donde ahora damos las probabilidades poblacionales de las cuatro combinaciones de resultados <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Car. 1}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp; Sí &amp; No \\\hline
Car. 2 &amp; Sí &amp; $p_{11}$ &amp; $p_{01}$ \\
&amp; No &amp; $p_{10}$ &amp; $p_{00}$
\\\hline
\end{tabular}
\]</span> De esta manera <span class="math inline">\(p_1=p_{11}+p_{10}\)</span> y <span class="math inline">\(p_2=p_{11}+p_{01}\)</span>. Entonces, <span class="math inline">\(p_1=p_2\)</span> es equivalente a<br />
<span class="math inline">\(p_{10}=p_{01}\)</span> y cualquier hipótesis alternativa se traduce en la misma desigualdad, pero para <span class="math inline">\(p_{10}=p_{01}\)</span>: <span class="math inline">\(p_1\neq p_2\)</span> es equivalente a <span class="math inline">\(p_{10}\neq p_{01}\)</span>; <span class="math inline">\(p_1&lt; p_2\)</span> es equivalente a <span class="math inline">\(p_{10}&lt; p_{01}\)</span>; y <span class="math inline">\(p_1&gt; p_2\)</span> es equivalente a <span class="math inline">\(p_{10}&gt; p_{01}\)</span>. Por lo tanto podemos traducir el contraste sobre <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span> al mismo contraste sobre <span class="math inline">\(p_{10}\)</span> y <span class="math inline">\(p_{01}\)</span>. La gracia ahora está en que si la hipótesis nula <span class="math inline">\(p_{10}=p_{01}\)</span> es cierta, entonces, en el total de {casos discordantes}, el número de sujetos en los que la característica 1 da Sí y la característica 2 da No sigue una ley binomial con <span class="math inline">\(p=0.5\)</span>. Por lo tanto, podemos efectuar el contraste usando un test binomial exacto tomando como muestra los casos discordantes, de tamaño <span class="math inline">\(b+c\)</span>, como éxitos los sujetos que han dado Sí en la característica 1 y No en la característica 2, de tamaño <span class="math inline">\(c\)</span>, con proporción a contrastar <span class="math inline">\(p=0.5\)</span> y con hipótesis alternativa la que corresponda. La ventaja de este test es que su validez no requiere de ninguna hipótesis sobre los tamaños de las muestras. El inconveniente es que el intervalo de confianza que nos dará será para <span class="math inline">\(p_{10}/(p_{10}+p_{01})\)</span>, y no permite obtener un intervalo de confianza para la diferencia o el cociente de las probabilidades <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span> de interés.</p>

<div class="example">
<span id="exm:unnamed-chunk-58" class="example"><strong>Ejemplo 1.19  </strong></span>Usemos el test binomial para llevar a cabo el contraste bilateral del Ejemplo <a href="chap-contrastes.html#exm:asma1">1.18</a>. Habíamos obtenido 30+48=78 casos discordantes, de los que 48 eran casos en los que el tratamiento A había dado Sí y el tratamiento B había dado No.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(<span class="dv">48</span>, <span class="dv">78</span>, <span class="dt">p=</span><span class="fl">0.5</span>)</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  48 and 78
## number of successes = 48, number of trials = 78, p-value = 0.05354
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4983310 0.7233984
## sample estimates:
## probability of success 
##              0.6153846</code></pre>
<p>Obtenemos de nuevo un p-valor en la zona de penumbra, ligeramente superior a 0.05.</p>

<div class="example">
<span id="exm:unnamed-chunk-60" class="example"><strong>Ejemplo 1.20  </strong></span>Para determinar si un test casero de VIH basado en un frotis bucal da más positivos (y seguramente serán falsos positivos) que el test de VIH de referencia, basado en una analítica de sangre que detecta la presencia del virus, se tomó una muestra aleatoria de 241 individuos en situación de riesgo, y a todos se les realizaron ambos tests. Los resultados se resumen en la tabla siguiente: <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Test estándar}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp; Positivo &amp; Negativo \\\hline
Test &amp; Positivo &amp; 72 &amp; 10 \\
casero &amp; Negativo &amp; 2 &amp; 157
\\\hline
\end{tabular}
\]</span>
</div>

<p>Si llamamos <span class="math inline">\(p_{c}\)</span> a la probabilidad de que el test casero dé positivo y <span class="math inline">\(p_{e}\)</span> a la probabilidad de que el test estándar dé positivo, queremos realizar el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_{e}=p_{c}\\
H_{1}:p_{e}&lt; p_{c}
\end{array}\right.
\]</span> Como el número de casos discordantes es pequeño (10+2=12), usaremos el test binomial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(<span class="dv">2</span>, <span class="dv">12</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="dt">p=</span><span class="fl">0.5</span>)</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  2 and 12
## number of successes = 2, number of trials = 12, p-value = 0.01929
## alternative hypothesis: true probability of success is less than 0.5
## 95 percent confidence interval:
##  0.0000000 0.4381054
## sample estimates:
## probability of success 
##              0.1666667</code></pre>
<p>Hay evidencia significativa de que, efectivamente, el test casero da positivo en más ocasiones que el de referencia.</p>
</div>
<div id="calculo-de-la-potencia-de-un-contraste" class="section level2">
<h2><span class="header-section-number">1.5</span> Cálculo de la potencia de un contraste</h2>
<p>La <strong>potencia</strong> de un contraste de hipótesis es la probabilidad de aceptar la hipótesis alternativa si es verdadera. Es decir, si llamamos <strong>error de tipo II</strong> a no rechazar la hipótesis nula cuando la alternativa es verdadera, la potencia del test es 1 menos la probabilidad de cometer un error de tipo II; usualmente, la probabilidad de cometer un error de tipo II se denota por <span class="math inline">\(\beta\)</span>, y por lo tanto la potencia es <span class="math inline">\(1-\beta\)</span>. Así pues, cuánto más alta sea la potencia de un contraste, menor será la probabilidad de cometer un error de tipo II y, por lo tanto, más fiable será el contraste.</p>
<p>La potencia de un contraste está relacionada con la llamada <strong>magnitud del efecto</strong>. En un contraste, el <strong>efecto</strong> es la diferencia entre el valor estimado del parámetro a partir de la muestra usada y el valor que se da a dicho parámetro como hipótesis nula: por ejemplo, en el contraste de una media, la diferencia entre la media muestral <span class="math inline">\(\overline{x}\)</span> y el valor contrastado <span class="math inline">\(\mu_0\)</span>; o, en el contraste de dos medias, la diferencia entre las dos medias muestrales. Se rechaza entonces la hipótesis nula si el efecto observado es tan grande que es muy improbable cuando la hipótesis nula es verdadera. Pero recordad que, en realidad, no se tiene en cuenta si el efecto observado ha sido grande o no por si mismo, solo si es significativo, es decir, si es improbable cuando la hipótesis nula es verdadera. Entonces, sin entrar en detalle, digamos que la <strong>magnitud del efecto</strong> es una medida estadística específica del tamaño del efecto observado respecto de su valor esperado. La fórmula para calcular la magnitud del efecto depende del contraste y del estadístico usado.</p>
<p>Para cada tipo de test se han definido unos valores de la magnitud del efecto considerados como “pequeño”, “mediano” y “grande” por convenio. Estos valores se obtienen con R con la función <code>cohen.ES</code> del paquete <strong>pwr</strong> aplicada al tipo de test (entrado en el parámetro <code>test</code>: por ejemplo, <code>test=&quot;t&quot;</code> para un test t usando <code>t.test</code>, o <code>test=&quot;p&quot;</code> para un test aproximado de proporciones usando <code>prop.test</code>) y el tipo de magnitud esperada (especificando en el parámetro <code>size</code> si esperamos que sea <code>&quot;small&quot;</code>, <code>&quot;medium&quot;</code> o <code>&quot;large&quot;</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pwr)
<span class="kw">cohen.ES</span>(<span class="dt">test=</span><span class="st">&quot;t&quot;</span>,<span class="dt">size=</span><span class="st">&quot;small&quot;</span>) <span class="co">#Magnitud pequeña en un t.test</span></code></pre></div>
<pre><code>## 
##      Conventional effect size from Cohen (1982) 
## 
##            test = t
##            size = small
##     effect.size = 0.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.ES</span>(<span class="dt">test=</span><span class="st">&quot;p&quot;</span>,<span class="dt">size=</span><span class="st">&quot;medium&quot;</span>) <span class="co">#Magnitud media en un prop.test</span></code></pre></div>
<pre><code>## 
##      Conventional effect size from Cohen (1982) 
## 
##            test = p
##            size = medium
##     effect.size = 0.5</code></pre>
<p>Así pues, en un contraste de hipótesis intervienen cuatro cantidades fundamentales:</p>
<ul>
<li><p>El <strong>tamaño</strong> de la muestra, <span class="math inline">\(n\)</span>: el número de observaciones que usamos en el contraste.</p></li>
<li><p>El <strong>nivel de significación</strong>, <span class="math inline">\(\alpha\)</span>: la probabilidad de rechazar la hipótesis nula si es cierta.</p></li>
<li><p>La <strong>potencia</strong>, <span class="math inline">\(1-\beta\)</span>: la probabilidad de rechazar la hipótesis nula si la hipótesis alternativa es cierta.</p></li>
<li><p>La <strong>magnitud del efecto</strong>: un valor que cuantifica la diferencia entre el parámetro estimado a partir de la muestra y su valor en la hipótesis nula.</p></li>
</ul>
<p>El tamaño de la muestra y el nivel de significación están bajo el control del investigador; sin embargo, la potencia del contraste y la magnitud del efecto afectan al contraste de forma más indirecta y su control escapa al investigador. Por ejemplo, si se relaja el nivel de significación, la potencia aumenta. De forma similar, si incrementamos el tamaño de la muestra, también incrementamos la potencia. De hecho, las cuatro cantidades anteriores no son independientes, sino que, a partir de tres cualesquiera de ellas, se puede calcular la cuarta. Las funciones del paquete <strong>pwr</strong> permiten realizar estos cálculos para los contrastes de medias y proporciones.</p>
<p>Las funciones de dicho paquete que por ahora nos interesan en este sentido son las siguientes:</p>
<ul>
<li><p><code>pwr.t.test</code>, para utilizar en tests t de una media, de dos medias usando muestras emparejadas o de dos medias usando muestras independientes del mismo tamaño.</p></li>
<li><p><code>pwr.t2n.test</code>, para utilizar en tests t de dos medias usando muestras independientes de distinto tamaño.</p></li>
<li><p><code>pwr.p.test</code>, para utilizar en contrastes aproximados de una proporción.</p></li>
<li><p><code>pwr.2p.test</code>, para utilizar en contrastes aproximados de dos proporciones usando muestras independientes del mismo tamaño.</p></li>
<li><p><code>pwr.2p2n.test</code>, para utilizar en contrastes aproximados de dos proporciones usando muestras de distinto tamaño.</p></li>
</ul>
<p>Estas funciones tienen los parámetros básicos siguientes:</p>
<ul>
<li><p><code>n</code>: el tamaño de la muestra (o de las muestras cuando son del mismo tamaño)</p></li>
<li><p><code>n1</code> y <code>n2</code>: los tamaños de las dos muestras en <code>pwr.2p2n.test} y</code>pwr.t2n.test}</p></li>
<li><code>d</code> (en las dos primeras) o <code>h</code> (en las tres últimas): la magnitud del efecto</li>
<li><code>sig.level</code>: el nivel de significación <span class="math inline">\(\alpha\)</span></li>
<li><code>power</code>: la potencia <span class="math inline">\(1-\beta\)</span></li>
<li><code>type</code> (en la primera): el tipo de contraste; sus posibles valores son <code>&quot;one.sample&quot;</code> (para contrastes de una muestra), <code>&quot;two.sample&quot;</code> (para contrastes de dos muestras independientes), o <code>&quot;paired&quot;</code> (para contrastes de dos muestras emparejadas)</li>
<li><p><code>alternative</code>: el tipo de hipótesis alternativa, con sus valores usuales</p></li>
</ul>
<p>Si, en una cualquiera de estas funciones se especifican todos los parámetros <code>n</code> (o <code>n1</code> y <code>n2</code>), <code>d</code> (o <code>h</code>), <code>sig.level</code> y <code>power</code> menos uno, la función da el valor del parámetro que falta.</p>
<p>Veamos algunos ejemplos de uso.</p>

<div class="example">
<p><span id="exm:norm1bis.pot" class="example"><strong>(#exm:norm1bis.pot) </strong></span>Queremos calcular la potencia del contraste llevado a cabo en el Ejemplo <a href="chap-contrastes.html#exm:norm1bis">1.1</a>. Se trataba de un contraste bilateral de una media usando un test t, por lo que utilizaremos la función <code>pwr.t.test</code>. Los parámetros que le entraremos son:</p>
</div>

<ul>
<li><p><code>n</code>, el tamaño de la muestra; en este ejemplo, <span class="math inline">\(n=25\)</span>.</p></li>
<li><p><code>d</code>, la magnitud del efecto. Para tests t de una media e hipótesis nula <span class="math inline">\(H_0: \mu = \mu_0\)</span>, la magnitud del efecto se calcula con la fórmula <span class="math display">\[
d=\frac{\overline{x}-\mu_0}{\widetilde{s}_x}.
\]</span> En nuestro ejemplo, <span class="math inline">\(d=\frac{|2.8048-2|}{0.68064}\approx 1.1824\)</span>.</p></li>
<li><p><code>sig.level</code>, el nivel de significación <span class="math inline">\(\alpha\)</span>; en este ejemplo, <span class="math inline">\(\alpha=0.05\)</span>.</p></li>
</ul>
<p>Además como es un contraste bliateral de una media, especificaremos <code>type=&quot;one.sample&quot;</code> y <code>alternative=&quot;two.sided&quot;</code> (esto último en realidad no hace falta: como siempre, este es su valor por defecto).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x=<span class="kw">c</span>(<span class="fl">2.2</span>,<span class="fl">2.66</span>,<span class="fl">2.74</span>,<span class="fl">3.41</span>,<span class="fl">2.46</span>,<span class="fl">2.96</span>,<span class="fl">3.34</span>,<span class="fl">2.16</span>,<span class="fl">2.46</span>,<span class="fl">2.71</span>,<span class="fl">2.04</span>,
  <span class="fl">3.74</span>,<span class="fl">3.24</span>,<span class="fl">3.92</span>,<span class="fl">2.38</span>,<span class="fl">2.82</span>,<span class="fl">2.2</span>,<span class="fl">2.42</span>,<span class="fl">2.82</span>,<span class="fl">2.84</span>,<span class="fl">4.22</span>,<span class="fl">3.64</span>,<span class="fl">1.77</span>,
  <span class="fl">3.44</span>,<span class="fl">1.53</span>)
mag.ef=<span class="kw">abs</span>(<span class="kw">mean</span>(x)<span class="op">-</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">sd</span>(x) <span class="co">#Magnitud del efecto</span>
<span class="kw">pwr.t.test</span>(<span class="dt">n=</span><span class="dv">25</span>, <span class="dt">d=</span>mag.ef, <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">type=</span><span class="st">&quot;one.sample&quot;</span>, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 25
##               d = 1.18241
##       sig.level = 0.05
##           power = 0.9998934
##     alternative = two.sided</code></pre>
<p>Obtenemos que la potencia del test es prácticamente 1.</p>
<p>Si estuviéramos diseñando el experimento y quisiéramos calcular el tamaño mínimo de una muestra para tener un nivel de significación del 5% y potencia del 99%, suponiendo *a priori} que la magnitud del efecto esperado fuera grande, entraríamos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.ES</span>(<span class="dt">test=</span><span class="st">&quot;t&quot;</span>,<span class="dt">size=</span><span class="st">&quot;large&quot;</span>) <span class="co">#Qué vale la magnitud del efecto grande?</span></code></pre></div>
<pre><code>## 
##      Conventional effect size from Cohen (1982) 
## 
##            test = t
##            size = large
##     effect.size = 0.8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pwr.t.test</span>(<span class="dt">d=</span><span class="fl">0.8</span>, <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">power=</span><span class="fl">0.99</span>,  
   <span class="dt">type=</span><span class="st">&quot;one.sample&quot;</span>)</code></pre></div>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 30.71433
##               d = 0.8
##       sig.level = 0.05
##           power = 0.99
##     alternative = two.sided</code></pre>
<p>Bastarían 31 observaciones para tener la potencia deseada</p>

<div class="example">
<span id="exm:trampas1bis" class="example"><strong>Ejemplo 1.21  </strong></span>Vamos a calcular la potencia del contraste <span class="math display">\[
\left\{
\begin{array}{l} 
 H_0:p_v=p_n\\
 H_1:p_v&lt;p_n
 \end{array}
 \right.
 \]</span> del Ejemplo <a href="chap-contrastes.html#exm:trampas1">1.16</a>. En este caso, usamos la función <code>pwr.2p.test</code>, ya que usamos dos muestras del mismo tamaño, y le entramos los parámetros siguientes:
</div>

<ul>
<li><p><code>n</code>, el tamaño de las muestras; en este ejemplo, <span class="math inline">\(n=60\)</span>.</p></li>
<li><p><code>h</code>, la magnitud del efecto. Para calcularla,<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> usamos la función <code>ES.h</code> del mismo paquete <strong>pwr</strong> y que se aplica a las proporciones muestrales de éxitos de las dos muestras: en este ejemplo, <span class="math inline">\(\widehat{p}_v=0.67\)</span> y <span class="math inline">\(\widehat{p}_n =0.8\)</span>.</p></li>
<li><p><code>sig.level</code>, el nivel de significación, 0.05.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mag.ef=<span class="kw">ES.h</span>(<span class="fl">0.67</span>,<span class="fl">0.8</span>) <span class="co">#Magnitud del efecto</span>
mag.ef  <span class="co">#Por curiosidad</span></code></pre></div>
<pre><code>## [1] -0.2965842</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pwr.2p.test</span>(<span class="dt">h=</span>mag.ef, <span class="dt">n=</span><span class="dv">60</span>, <span class="dt">sig.level=</span><span class="fl">0.05</span>, 
   <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##      Difference of proportion power calculation for binomial distribution (arcsine transformation) 
## 
##               h = -0.2965842
##               n = 60
##       sig.level = 0.05
##           power = 0.4918641
##     alternative = less
## 
## NOTE: same sample sizes</code></pre>
<p>Hemos obtenido una potencia de, aproximadamente, un 49%.</p>
<p>Si estuviéramos diseñando el experimento y quisiéramos calcular el tamaño de las muestras necesario para tener una potencia del 90% al nivel de significación del 5% y esperando una magnitud del efecto pequeña (porque esperamos una mejora con las nuevas trampas, pero solo pequeña), entraríamos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.ES</span>(<span class="dt">test=</span><span class="st">&quot;p&quot;</span>,<span class="dt">size=</span><span class="st">&quot;small&quot;</span>)</code></pre></div>
<pre><code>## 
##      Conventional effect size from Cohen (1982) 
## 
##            test = p
##            size = small
##     effect.size = 0.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pwr.2p.test</span>(<span class="dt">h=</span><span class="op">-</span><span class="fl">0.2</span>, <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">power=</span><span class="fl">0.9</span>, 
   <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##      Difference of proportion power calculation for binomial distribution (arcsine transformation) 
## 
##               h = -0.2
##               n = 428.1924
##       sig.level = 0.05
##           power = 0.9
##     alternative = less
## 
## NOTE: same sample sizes</code></pre>
<p>Tendríamos que usar dos muestras de <span class="math inline">\(429\)</span> cucarachas cada una. Observad que en <code>pwr.2p.test</code> hemos entrado en <code>h</code> la magnitud del efecto en negativo: esto es debido a que usamos <code>alternative=&quot;less&quot;</code> y por lo tanto esperamos que la primera proporción sea menor que la segunda.</p>

<div class="example">
<p><span id="exm:fumarbis" class="example"><strong>Ejemplo 1.22  </strong></span>En el contraste <span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_n=\mu_f\\
H_{1}:\mu_n&gt; \mu_f
\end{array}\right.
\]</span> del Ejemplo <a href="chap-contrastes.html#exm:fumar">1.5</a>, ¿qué tamaño de la muestra de mujeres fumadoras tendríamos que tomar si usáramos una muestra de 100 no fumadoras, quisiéramos una potencia del 90% y un nivel de significación del 5% y esperáramos una magnitud del efecto media?</p>
</div>

<p>Como es un contraste de dos medias independientes y los tamaños de las muestras pueden ser diferentes, usaremos la función <code>pwr.t2n.test</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.ES</span>(<span class="dt">test=</span><span class="st">&quot;p&quot;</span>,<span class="dt">size=</span><span class="st">&quot;medium&quot;</span>)</code></pre></div>
<pre><code>## 
##      Conventional effect size from Cohen (1982) 
## 
##            test = p
##            size = medium
##     effect.size = 0.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pwr.t2n.test</span>(<span class="dt">n1=</span><span class="dv">100</span>, <span class="dt">d=</span><span class="fl">0.5</span>,  <span class="dt">sig.level=</span><span class="fl">0.05</span>, <span class="dt">power=</span><span class="fl">0.9</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>## 
##      t test power calculation 
## 
##              n1 = 100
##              n2 = 52.82509
##               d = 0.5
##       sig.level = 0.05
##           power = 0.9
##     alternative = greater</code></pre>
<p>Bastaría estudiar 53 madres fumadoras.</p>
</div>
<div id="guia-rapida" class="section level2">
<h2><span class="header-section-number">1.6</span> Guía rápida</h2>
<ul>
<li><p><code>t.test</code>, para realizar tests t para contrastar una o dos medias (tanto usando muestras independientes como emparejadas)</p></li>
<li><p><code>SIGN.test</code>, para realizar un test de signos para contrastar una mediana</p></li>
<li><p><code>wilcox.test</code>, para realizar tests de Wilcoxon y de Mann-Whitney para contrastar una o dos medias, o mejor, medianas (tanto usando muestras independientes como emparejadas)</p></li>
<li><p><code>sigma.test</code>, para realizar tests <span class="math inline">\(\chi^2\)</span> para contrastar una varianza (o una desviación típica)</p></li>
<li><p><code>var.test</code>, para realizar tests F para contrastar dos varianzas (o dos desviaciones típicas)</p></li>
<li><p><code>fligner.test</code>, para realizar tests no paramétricos de Fligner-Killeen para contrastar dos varianzas (o dos desviaciones típicas)</p></li>
<li><p><code>binom.test</code>, para realizar tests binomiales exactos para contrastar una proporción</p></li>
<li><p><code>prop.test</code>, para realizar tests aproximados para contrastar una proporción o dos proporciones de poblaciones usando muestras independientes</p></li>
<li><p><code>fisher.test</code>, para realizar tests exactos de Fisher para contrastar dos proporciones usando muestras independientes</p></li>
<li><p><code>mcnemar.test</code>, para realizar tests bilaterales de McNemar para contrastar dos proporciones usando muestras emparejadas</p></li>
</ul>
<p>Como veremos, la mayoría de estas funciones tienen una sintaxis similar (salvo particularidades debidas al propio test, como por ejemplo qué contrasta o a qué información se aplica). El grueso del capítulo está dedicado a ejemplos de uso de estas funciones. En la última sección tratamos el problema de cómo calcular la potencia de un contraste, o el tamaño mínimo de las muestras para garantizar una potencia dada, en el caso de los contrastes más populares, usando las funciones del paquete <strong>pwr</strong>.</p>
<p>Recordemos en lo que sigue que el <strong>nivel de significación</strong> <span class="math inline">\(\alpha\)</span> de un contraste es la probabilidad de cometer un <strong>error de tipo I</strong>, es decir, la probabilidad de rechazar la hipótesis nula si es verdadera. El <strong>nivel de confianza</strong> es el complementario del nivel de significación, <span class="math inline">\(1-\alpha\)</span>, y por lo tanto es la probabilidad de no rechazar la hipótesis nula si es verdadera.</p>
</div>
<div id="ejercicios" class="section level2">
<h2><span class="header-section-number">1.7</span> Ejercicios</h2>
<div id="ejercicios-1" class="section level3 unnumbered">
<h3>Ejercicios</h3>
<p><strong>(1)</strong> Para satisfacer las necesidades respiratorias de los peces de agua caliente, el contenido de oxígeno disuelto debe presentar un promedio de 6.5 partes por millón (ppm), con una desviación típica no mayor de 1.2 ppm. Cuando la temperatura del agua crece, el oxígeno disuelto disminuye, y esto causa la asfixia del pez.</p>
<p>Se realizó un estudio sobre los efectos del calor en verano en el contenido de oxígeno disuelto en un gran lago. Después de un período particularmente caluroso, se tomaron muestras de agua en <span class="math inline">\(35\)</span> lugares aleatoriamente seleccionados en el lago, y se determinó el contenido de oxígeno disuelto. Los resultados (en ppm) fueron los siguientes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">O2=<span class="kw">c</span>(<span class="fl">9.1</span>,<span class="fl">6.8</span>,<span class="fl">7.0</span>,<span class="fl">7.5</span>,<span class="fl">8.7</span>,<span class="fl">3.2</span>,<span class="fl">5.4</span>,<span class="fl">8.1</span>,<span class="fl">4.4</span>,<span class="fl">5.1</span>,<span class="fl">6.2</span>,<span class="fl">6.9</span>,<span class="fl">6.9</span>,<span class="fl">4.3</span>,
    <span class="fl">8.0</span>,<span class="fl">5.3</span>,<span class="fl">6.2</span>,<span class="fl">6.4</span>,<span class="fl">7.8</span>,<span class="fl">5.8</span>,<span class="fl">6.9</span>,<span class="fl">7.7</span>,<span class="fl">5.2</span>,<span class="fl">5.8</span>,<span class="fl">6.3</span>,<span class="fl">5.9</span>,<span class="fl">8.5</span>,<span class="fl">7.5</span>,<span class="fl">8.9</span>,
    <span class="fl">5.6</span>,<span class="fl">6.6</span>,<span class="fl">5.3</span>,<span class="fl">5.7</span>,<span class="fl">6.9</span>,<span class="fl">6.6</span>)</code></pre></div>
<p>Suponemos que estos contenidos de oxígeno siguen una distribución normal.</p>
<ol style="list-style-type: lower-alpha">
<li>¿Hay evidencia de que el contenido medio de oxígeno en el lago sea inferior al nivel aceptable de <span class="math inline">\(6.5\)</span> ppm?</li>
<li>¿Hay evidencia de que la desviación típica del contenido de oxígeno en el lago sea superior a <span class="math inline">\(1.2\)</span> ppm?</li>
</ol>
<p><strong>(2)</strong> Los angiogramas son la técnica estándar para diagnosticar un ictus, pero tienen un ligero riesgo de mortalidad (inferior al 1%). Algunos investigadores han propuesto usar una prueba PET para diagnosticar el ictus de manera no invasiva. Sobre 64 pacientes ingresados en urgencias con síntomas de ictus se usaron ambas técnicas de diagnóstico. Los resultados obtenidos se resumen en la tabla siguiente: <span class="math display">\[
\begin{tabular}{|c|c|cc|}
\cline{3-4}
\multicolumn{2}{c|}{}&amp; \multicolumn{2}{|c|} {Angiograma}\\\cline{3-4}
\multicolumn{2}{c|}{} &amp; Positivo &amp; Negativo \\\hline
PET &amp; Positivo &amp; 32 &amp; 8 \\
 &amp; Negativo &amp; 3 &amp; 21
\\\hline
\end{tabular}
\]</span> Contrastad si ambas técnicas de diagnóstico tienen la misma probabilidad de dar positivo.</p>
</div>
<div id="modelo-de-test" class="section level3 unnumbered">
<h3>Modelo de test</h3>
<p>\begin{enumerate}[(1)]</p>
<ul>
<li><p>Tenemos una muestra de una población normal formada por los números <span class="math inline">\(2,5,3,5,6,6,7,\)</span> <span class="math inline">\(2\)</span>. Usando la función `t.test}, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste <span class="math inline">\(H_0: \mu=4\)</span> contra <span class="math inline">\(H_1:\mu \neq 4\)</span> y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco.</p></li>
<li><p>Tenemos dos muestras de poblaciones normales, <span class="math inline">\(x_1\)</span>: <span class="math inline">\(2,5,3,5,6,6,7,2\)</span> y <span class="math inline">\(x_2\)</span>: <span class="math inline">\(3,2,5,4,2,2\)</span>, <span class="math inline">\(4,5,1,6,2\)</span>. Usando la función `t.test}, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste <span class="math inline">\(H_0: \mu_1=\mu_2\)</span> contra <span class="math inline">\(H_1:\mu_1&gt;\mu_2\)</span> suponiendo que las varianzas son diferentes y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.1. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco.</p></li>
<li><p>Tenemos dos muestras de poblaciones normales, <span class="math inline">\(x_1\)</span>: <span class="math inline">\(2,5,3,5,6,6,7,2\)</span> y <span class="math inline">\(x_2\)</span>: <span class="math inline">\(3,2,10,9,2\)</span>, <span class="math inline">\(2,4,5,1,10,2\)</span>. Usando la función `var.test}, calculad los extremos inferior y superior de un intervalo de confianza del 95% para <span class="math inline">\(\sigma_1^2/\sigma_2^2\)</span> (redondeados a 3 cifras decimales, sin ceros innecesarios a la derecha) y decid (contestando SI, sin acento, o NO) si en el contraste <span class="math inline">\(H_0: \sigma_1=\sigma_2\)</span> contra <span class="math inline">\(H_1:\sigma_1 \neq \sigma_2\)</span> podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las tres respuestas en este orden, separadas por un único espacio en blanco.</p></li>
<li><p>Tenemos dos variables aleatorias de Bernoulli de proporciones poblacionales <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, respectivamente. En una muestra de 100 observaciones de la primera hemos obtenido 20 éxitos, y en una muestra de 150 observaciones de la segunda, hemos obtenido 40 éxitos. Usando la función `prop.test}, calculad el p-valor (redondeado a 3 cifras decimales, sin ceros innecesarios a la derecha) del contraste <span class="math inline">\(H_0: p_1=p_2\)</span> contra <span class="math inline">\(H_1:p_1 &lt;p_2\)</span> y decid (contestando SI, sin acento, o NO) si podemos rechazar la hipótesis nula en favor de la alternativa a un nivel de significación de 0.05. Tenéis que dar las dos respuestas en este orden, separadas por un único espacio en blanco.</p></li>
</ul>
</div>
<div id="respuestas" class="section level3 unnumbered">
<h3>Respuestas</h3>
<p>\begin{enumerate}[(1)]</p>
<ul>
<li>0.487 NO</li>
</ul>
<p>%Nosotros hemos hecho %<code>{r} %&gt; x=c(2,5,3,5,6,6,7,2) %&gt; round(t.test(x,mu=4,alternative=&quot;two.sided&quot;)$p.value,3) %[1] 0.487 %</code></p>
<ul>
<li>0.083 SI</li>
</ul>
<p>%Nosotros hemos hecho %<code>{r} %&gt; x1=c(2,5,3,5,6,6,7,2) %&gt; x2=c(3,2,5,4,2,2,4,5,1,6,2) %&gt; round(t.test(x1,x2,conf.level=0.9, % alternative=&quot;greater&quot;)$p.value,3) %[1] 0.083 %</code></p>
<ul>
<li>0.078 1.465 NO</li>
</ul>
<p>%Nosotros hemos hecho %<code>{r} %&gt; x1=c(2,5,3,5,6,6,7,2) %&gt; x2=c(3,2,10,9,2,2,4,5,1,10,2) %&gt; round(var.test(x1,x2)$conf.int,3) %[1] 0.078 1.465 %attr(,&quot;conf.level&quot;) %[1] 0.95 %</code></p>
<ul>
<li>0.145 NO</li>
</ul>
<p>%Nosotros hemos hecho %<code>{r} %&gt; prop.test(c(20,40),c(100,150),alternative=&quot;less&quot;)$p.value %[1] 0.1450309 %</code></p>

</div>
</div>
</div>












<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>En realidad, se sabe que si las dos muestras provienen de poblaciones normales y son del mismo tamaño, el test t tiende a dar la misma conclusión tanto si se supone que las dos varianzas son iguales como si se supone que son diferentes (véase C. A. Markowski y E. P. Markowski, “Conditions for the Effectiveness of a Preliminary Test of Variance,” <em>The American Statistician</em> 44 (1990), pp. 322-326). Por lo tanto, si en este caso supiéramos que estas longitudes tienen distribuciones normales, bastaría realizar uno de los dos tests.<a href="chap-contrastes.html#fnref1">↩</a></p></li>
<li id="fn2"><p>Las podéis encontrar en el <em>dataframe</em> <code>sleep</code> de la instalación básica de R, aunque no lo vamos a usar.<a href="chap-contrastes.html#fnref2">↩</a></p></li>
<li id="fn3"><p>En realidad, la hipótesis nula de este test, la que no rechazamos, es que “Es igual de probable que un hijo de madre de 20 años pese más que un hijo de madre de 30 años que al revés”, pero no vamos a entrar en este nivel de precisión. Ambas hipótesis nulas quieren representar lo que realmente nos interesa confirmar o desmentir: “Los hijos de madres de 20 años pesan lo mismo que los de madres de 30 años”.<a href="chap-contrastes.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Véanse: E. S. Pearson, “The analysis of variance in cases of non-normal variation,” <em>Biometrika</em> 23 (1931), pp. 114-133; G. E. P. Box, “Non-normality and tests on variances,” <em>Biometrika</em> 40 (1953), pp. 318-335.<a href="chap-contrastes.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Por si a alguien le interesa, la fórmula para esta magnitud del efecto es <span class="math display">\[
h=2\left(\arcsin\big(\sqrt{\widehat{p}_1}\,\big)-\arcsin\big(\sqrt{\widehat{p}_2}\,\big)\right),
\]</span> siendo <span class="math inline">\(\widehat{p}_1\)</span> y <span class="math inline">\(\widehat{p}_2\)</span> las proporciones muestrales de éxitos de las dos muestras.<a href="chap-contrastes.html#fnref5">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cescrossello/AprendeR-II/edit/master/05-CcontrastesI.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["AprendeR-Parte-II.pdf", "AprendeR-Parte-II.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
